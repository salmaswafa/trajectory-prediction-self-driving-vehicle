{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    },
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use This if you are using Kaggle Notebook"
      ],
      "metadata": {
        "id": "-n-C_P-zs-pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": [],
        "id": "F4_wHjhZs-pa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset to your folder or use it on kaggle notebook directly\n",
        "\n",
        "train_file = np.load('/your_folder/cse-251-b-2025/train.npz')\n",
        "# train_file = np.load('/kaggle/input/cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('/your_folder/test_input.npz')\n",
        "# test_file = np.load('/kaggle/input/cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": [],
        "id": "09texa_os-pc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": [],
        "id": "ckJbGP_ds-pc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " # say you have a model trained. we write a dummy model just to show useage\n",
        "\n",
        "def dummy_model(input_data):\n",
        "    return np.ones((2100, 1, 60, 2))\n",
        "\n",
        "\n",
        "output = dummy_model(test_data)\n",
        "output.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:41.339052Z",
          "iopub.status.busy": "2025-04-01T17:39:41.338689Z",
          "iopub.status.idle": "2025-04-01T17:39:41.348089Z",
          "shell.execute_reply": "2025-04-01T17:39:41.346792Z"
        },
        "papermill": {
          "duration": 0.015255,
          "end_time": "2025-04-01T17:39:41.349879",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.334624",
          "status": "completed"
        },
        "tags": [],
        "id": "k1ZWD-EEs-pd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape to fit desired format: (2100, 1, 60, 2) -> (12600, 2)\n",
        "dummy_output = output.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(dummy_output, columns=['x', 'y'])\n",
        "\n",
        "# adding a necessary step to match index of your prediction to that of the solution key\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('dummy_submission.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:41.358147Z",
          "iopub.status.busy": "2025-04-01T17:39:41.357784Z",
          "iopub.status.idle": "2025-04-01T17:39:41.587769Z",
          "shell.execute_reply": "2025-04-01T17:39:41.586758Z"
        },
        "papermill": {
          "duration": 0.236496,
          "end_time": "2025-04-01T17:39:41.589803",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.353307",
          "status": "completed"
        },
        "tags": [],
        "id": "V6RnZeqLs-pd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split x and y for train data.\n",
        "\n",
        "train_x, train_y = train_data[..., :50, :], train_data[:, 0, 50:, :2]\n",
        "\n",
        "# get the average velocity of the prediction agent\n",
        "velocity_diff = train_x[...,1:, :2] - train_x[...,:-1, :2]\n",
        "print(velocity_diff.shape)\n",
        "\n",
        "constant_vel = np.mean(velocity_diff[:,0, :, :], axis=-2)\n",
        "print(constant_vel.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "px61QYuBs-pd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# create pred_y\n",
        "\n",
        "pred_y = np.zeros((10000, 60, 2))\n",
        "starting_point = train_x[:, 0, -1, :2] # shape (10000, 2)\n",
        "\n",
        "for t in range(60):\n",
        "    pred_y[:,t,:] = starting_point + (t+1) * constant_vel"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZNq4cd2ts-pe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate train loss\n",
        "\n",
        "mse = ((train_y - pred_y)**2).mean()\n",
        "print(mse)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Go_gVzJPs-pe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare submission\n",
        "\n",
        "\n",
        "# get the average velocity of the prediction agent\n",
        "velocity_diff = test_data[...,1:, :2] - test_data[...,:-1, :2]\n",
        "print(velocity_diff.shape)\n",
        "\n",
        "constant_vel = np.mean(velocity_diff[:,0, :, :], axis=-2)\n",
        "print(constant_vel.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9t9ZL7XSs-pe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# create pred_y for test set\n",
        "\n",
        "pred_y = np.zeros((2100, 60, 2))\n",
        "starting_point = test_data[:, 0, -1, :2]\n",
        "\n",
        "for t in range(60):\n",
        "    pred_y[:,t,:] = starting_point + (t+1) * constant_vel"
      ],
      "metadata": {
        "trusted": true,
        "id": "s-kYCIGGs-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape to fit desired format: (2100, 60, 2) -> (12600, 2)\n",
        "pred_output = pred_y.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "\n",
        "# adding a necessary step to match index of your prediction to that of the solution key\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('constant_vel_submission.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "bNq2Reg3s-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split x and y for train data.\n",
        "\n",
        "train_x, train_y = train_data[..., :50, :], train_data[:, 0, 50:, :2]\n",
        "\n",
        "print(train_x.shape, train_y.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5CxcJtU5s-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_features, output_features):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Define the layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(256, output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.mlp(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hLC6JXYCs-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total number of features after flattening\n",
        "input_features = 50 * 50 * 6  # = 5000\n",
        "output_features = 60 * 2\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model = MLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # For regression task\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wutVdErzs-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example of how to prepare data and train the model\n",
        "\n",
        "def train_model(model, x_train, y_train, batch_size=64, epochs=10):\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(x_train).reshape((-1, input_features))\n",
        "    y_train_tensor = torch.FloatTensor(y_train).reshape((-1, output_features))\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in tqdm(train_loader):\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "oK9mi4Nas-pf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, train_x, train_y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "41faFOm2s-pg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(X_test):\n",
        "    \"\"\"Make predictions with the trained model\"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features))\n",
        "        predictions = model(X_test_tensor).reshape((-1, 60, 2))\n",
        "    return predictions.numpy()\n",
        "\n",
        "# Save model\n",
        "def save_model(path=\"mlp_model.pth\"):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "# Load model\n",
        "def load_model(path=\"mlp_model.pth\"):\n",
        "    loaded_model = MLP()\n",
        "    loaded_model.load_state_dict(torch.load(path))\n",
        "    loaded_model.eval()\n",
        "    return loaded_model"
      ],
      "metadata": {
        "trusted": true,
        "id": "j2IsLzTEs-pg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pred_y = predict(test_data)\n",
        "\n",
        "pred_output = pred_y.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "\n",
        "# adding a necessary step to match index of your prediction to that of the solution key\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('mlp_baseline.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "SBzrfB_gs-pg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Now you can submit to the leaderboard!"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.003051,
          "end_time": "2025-04-01T17:39:41.596387",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.593336",
          "status": "completed"
        },
        "tags": [],
        "id": "R5ponqm0s-pg"
      }
    }
  ]
}