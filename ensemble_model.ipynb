{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"ensemble_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "train_file = np.load('../cse-251-b-2025/train.npz')\n",
    "\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('../cse-251-b-2025/test_input.npz')\n",
    "\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDatasetTrain_AngularAcc(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "        self.dt = 0.1  # seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        hist = scene[:, :50, :4].copy()  # (agents=50, time_seq=50, 5)\n",
    "        future = torch.tensor(scene[0, 50:, 0:4].copy(), dtype=torch.float32)  # (60, 2)\n",
    "\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                future[..., :2] = future[..., :2] @ R\n",
    "                future[..., 2:4] = future[..., 2:4] @ R\n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "                future[:, 2] *= -1\n",
    "\n",
    "        v = hist[..., 2:4]  # velocity\n",
    "        a = np.zeros_like(v)\n",
    "        a[..., 1:] = (v[..., 1:] - v[..., :-1]) / self.dt\n",
    "\n",
    "        theta = np.arctan2(v[..., 1], v[..., 0])[..., np.newaxis]\n",
    "        omega = np.zeros_like(theta)\n",
    "        omega[..., 1:] = (theta[..., 1:] - theta[..., :-1]) / self.dt\n",
    "\n",
    "        alpha = np.zeros_like(omega)\n",
    "        alpha[..., 1:] = (omega[..., 1:] - omega[..., :-1]) / self.dt\n",
    "\n",
    "        hist_aug = np.concatenate([hist, a, theta, omega, alpha], axis=-1)  # shape (50, 50, 9)\n",
    "\n",
    "        origin = hist_aug[0, 49, :2].copy()\n",
    "        hist_aug[..., :2] -= origin\n",
    "        hist_aug[..., :4] /= self.scale\n",
    "        hist_aug[..., 4:6] /= self.scale / self.dt        # ax, ay\n",
    "        hist_aug[..., 6] /= np.pi                         # θ ∈ [-π, π]\n",
    "        hist_aug[..., 7] /= (np.pi / self.dt)             # ω\n",
    "        hist_aug[..., 8] /= (np.pi / (self.dt ** 2))      # α\n",
    "        future[..., :2] = future[..., :2] - origin\n",
    "        future = future / self.scale\n",
    "\n",
    "        return Data(\n",
    "            x=torch.tensor(hist_aug, dtype=torch.float32),\n",
    "            y=future,\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        \n",
    "        \n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.dt = 0.1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hist = self.data[idx][:, :50, :4].copy()  # (50, 50, 4: [x, y, vx, vy])\n",
    "\n",
    "        v = hist[..., 2:4]\n",
    "        a = np.zeros_like(v)\n",
    "        a[..., 1:] = (v[..., 1:] - v[..., :-1]) / self.dt\n",
    "\n",
    "        theta = np.arctan2(v[..., 1], v[..., 0])[..., np.newaxis]\n",
    "        omega = np.zeros_like(theta)\n",
    "        omega[..., 1:] = (theta[..., 1:] - theta[..., :-1]) / self.dt\n",
    "\n",
    "        alpha = np.zeros_like(omega)\n",
    "        alpha[..., 1:] = (omega[..., 1:] - omega[..., :-1]) / self.dt\n",
    "\n",
    "        hist_aug = np.concatenate([hist, a, theta, omega, alpha], axis=-1)  # shape (50, 50, 9)\n",
    "\n",
    "        origin = hist_aug[0, 49, :2].copy()\n",
    "        hist_aug[..., :2] -= origin\n",
    "        hist_aug[..., :4] /= self.scale\n",
    "        hist_aug[..., 4:6] /= self.scale / self.dt\n",
    "        hist_aug[..., 6] /= np.pi\n",
    "        hist_aug[..., 7] /= (np.pi / self.dt)\n",
    "        hist_aug[..., 8] /= (np.pi / (self.dt ** 2))\n",
    "\n",
    "        return Data(\n",
    "            x=torch.tensor(hist_aug, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(251)\n",
    "np.random.seed(42)\n",
    "\n",
    "scale = 7.0\n",
    "\n",
    "N = len(train_data)\n",
    "val_size = int(0.1 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = TrajectoryDatasetTrain_AngularAcc(train_data[:train_size], scale=scale, augment=True)\n",
    "val_dataset = TrajectoryDatasetTrain_AngularAcc(train_data[train_size:], scale=scale, augment=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xy(pred_vel, origin=None):\n",
    "    dt = 0.1  # seconds per step\n",
    "    if origin:\n",
    "        pred_pos = [origin]  # list of (B, 1, 2)\n",
    "        for t in range(60):\n",
    "            next_pos = pred_pos[-1] + pred_vel[:, t:t+1, :] * dt  # (B, 1, 2)\n",
    "            pred_pos.append(next_pos)\n",
    "        \n",
    "        # Concatenate positions across time steps\n",
    "        pred_xy = torch.cat(pred_pos[1:], dim=1)  # skip initial origin, get (B, 60, 2)\n",
    "    else:\n",
    "        pred_pos = [0]\n",
    "        \n",
    "        for t in range(60):\n",
    "            next_vel = (pred_vel[:, t:t+1, :] - pred_pos[-1]) /dt\n",
    "            # next_pos = pred_pos[-1] + pred_vel[:, t:t+1, :] * dt  # (B, 1, 2)\n",
    "            pred_pos.append(next_vel)\n",
    "        pred_vxvy = torch.cat(pred_pos[1:], dim=1)  # skip initial origin, get (B, 60, 2)\n",
    "    return pred_vxvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_VXVY(pred_pos, origin=None):\n",
    "    dt = 0.1\n",
    "    pred_pos = pred_pos.reshape(-1, 60, 2)\n",
    "    B = pred_pos.shape[0]\n",
    "    zero_pos = torch.zeros((B, 1, 2), device=pred_pos.device, dtype=pred_pos.dtype)\n",
    "    pos = torch.cat([zero_pos, pred_pos], dim=1)\n",
    "    vel = torch.zeros_like(pos)                     # shape (B, 61, 2), with vel[:,0,:]=0\n",
    "    vel[:, 1:, :] = (pos[:, 1:, :] - pos[:, :-1, :]) / dt\n",
    "    pred_vxvy = vel[:, 1:, :]     # skip initial origin, get (B, 60, 2)\n",
    "    return pred_vxvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic model that should work\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Add multi-layer prediction head for better results\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_normal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = data.x[..., :5]\n",
    "        # x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
    "        \n",
    "        # Process through LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Extract final hidden state\n",
    "        features = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Process through prediction head\n",
    "        features = self.relu(self.fc1(features))\n",
    "        features = self.dropout(features)\n",
    "        out = self.fc2(features)\n",
    "        \n",
    "        # Reshape to (batch_size, 60, 2)\n",
    "        out_vel = convert_VXVY(out.view(-1, 60, 2))\n",
    "        return out_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic model that should work\n",
    "class VelocityModel(nn.Module):\n",
    "    # 2 layers 9.77 val\n",
    "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2, num_layers=1):\n",
    "        super(VelocityModel, self).__init__()\n",
    "        self.ego_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.neighbor_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Add multi-layer prediction head for better results\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim*2)\n",
    "        # TODO: remove dropout?\n",
    "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if 'weight' in name:\n",
    "        #         nn.init.xavier_normal_(param)\n",
    "        #     elif 'bias' in name:\n",
    "        #         nn.init.constant_(param, 0.0)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x = data.x[..., :5]\n",
    "        x = data.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        batch_size = x.size(0)\n",
    "        # x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
    "        \n",
    "        # EGO AGENT\n",
    "        ego_traj = x[:, 0, :, :]  # (batch, 50, 5)\n",
    "        # Process through LSTM\n",
    "        ego_lstm_out, _ = self.ego_encoder(ego_traj)\n",
    "        # Extract final hidden state\n",
    "        ego_features = ego_lstm_out[:, -1, :]\n",
    "        \n",
    "        # CLOSEST NEIGHBOR\n",
    "        # ---- DISTANCES TO OTHER AGENTS ----\n",
    "        ego_pos = x[:, 0, 49, :2].unsqueeze(1)  # (batch, 1, 2)\n",
    "        agent_pos = x[:, :, 49, :2]  # (batch, 50, 2)\n",
    "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
    "        dists[:, 0] = float('inf')  # mask out ego\n",
    "        \n",
    "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 3)\n",
    "        \n",
    "        # ---- ENCODE NEIGHBORS ----\n",
    "        neighbor_out_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            idx = neighbor_ids[:, i]  # (batch,)\n",
    "            neighbor_trajs = torch.stack([x[b, idx[b]] for b in range(batch_size)], dim=0)  # (batch, 50, 5)\n",
    "\n",
    "            neighbor_lstm_out, _ = self.neighbor_encoder(neighbor_trajs)  # both: (num_layers, batch, hidden_dim)\n",
    "\n",
    "            neighbor_out_list.append(neighbor_lstm_out[:, -1, :])\n",
    "\n",
    "        # ---- CONCATENATE HIDDEN AND CELL STATES ----\n",
    "        all_features = torch.cat([ego_features] + neighbor_out_list, dim=1)  # (num_layers, batch, hidden_dim * 4)\n",
    "        \n",
    "        # Process through prediction head\n",
    "        features = self.relu(self.fc1(all_features))\n",
    "        features = self.dropout(features)\n",
    "        out = self.fc2(features)\n",
    "        \n",
    "        # Reshape to (batch_size, 60, 2)\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic model that should work\n",
    "class AccelearationModel(nn.Module):\n",
    "    # 2 layers 9.77 val\n",
    "    def __init__(self, input_dim=8, hidden_dim=512, output_dim=60*2, num_layers=1):\n",
    "        super(AccelearationModel, self).__init__()\n",
    "        self.ego_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.neighbor_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Add multi-layer prediction head for better results\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim*2)\n",
    "        # TODO: remove dropout?\n",
    "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if 'weight' in name:\n",
    "        #         nn.init.xavier_normal_(param)\n",
    "        #     elif 'bias' in name:\n",
    "        #         nn.init.constant_(param, 0.0)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x = data.x[..., :5]\n",
    "        x = data.reshape(-1, 50, 50, self.input_dim)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        batch_size = x.size(0)\n",
    "        # x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
    "        \n",
    "        # EGO AGENT\n",
    "        ego_traj = x[:, 0, :, :]  # (batch, 50, 5)\n",
    "        # Process through LSTM\n",
    "        ego_lstm_out, _ = self.ego_encoder(ego_traj)\n",
    "        # Extract final hidden state\n",
    "        ego_features = ego_lstm_out[:, -1, :]\n",
    "        \n",
    "        # CLOSEST NEIGHBOR\n",
    "        # ---- DISTANCES TO OTHER AGENTS ----\n",
    "        ego_pos = x[:, 0, 49, :2].unsqueeze(1)  # (batch, 1, 2)\n",
    "        agent_pos = x[:, :, 49, :2]  # (batch, 50, 2)\n",
    "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
    "        dists[:, 0] = float('inf')  # mask out ego\n",
    "        \n",
    "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 3)\n",
    "        \n",
    "        # ---- ENCODE NEIGHBORS ----\n",
    "        neighbor_out_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            idx = neighbor_ids[:, i]  # (batch,)\n",
    "            neighbor_trajs = torch.stack([x[b, idx[b]] for b in range(batch_size)], dim=0)  # (batch, 50, 5)\n",
    "\n",
    "            neighbor_lstm_out, _ = self.neighbor_encoder(neighbor_trajs)  # both: (num_layers, batch, hidden_dim)\n",
    "\n",
    "            neighbor_out_list.append(neighbor_lstm_out[:, -1, :])\n",
    "\n",
    "        # ---- CONCATENATE HIDDEN AND CELL STATES ----\n",
    "        all_features = torch.cat([ego_features] + neighbor_out_list, dim=1)  # (num_layers, batch, hidden_dim * 4)\n",
    "        \n",
    "        # Process through prediction head\n",
    "        features = self.relu(self.fc1(all_features))\n",
    "        features = self.dropout(features)\n",
    "        out = self.fc2(features)\n",
    "        \n",
    "        # Reshape to (batch_size, 60, 2)\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic model that should work\n",
    "class AngularAccelerationModel(nn.Module):\n",
    "    # 2 layers 9.77 val\n",
    "    def __init__(self, input_dim=9, hidden_dim=512, output_dim=60*2, num_layers=1):\n",
    "        super(AngularAccelerationModel, self).__init__()\n",
    "        self.ego_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.neighbor_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Add multi-layer prediction head for better results\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim*2)\n",
    "        # TODO: remove dropout?\n",
    "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if 'weight' in name:\n",
    "        #         nn.init.xavier_normal_(param)\n",
    "        #     elif 'bias' in name:\n",
    "        #         nn.init.constant_(param, 0.0)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        # x = data.x[..., :5]\n",
    "        x = data.reshape(-1, 50, 50, self.input_dim)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        batch_size = x.size(0)\n",
    "        # x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
    "        \n",
    "        # EGO AGENT\n",
    "        ego_traj = x[:, 0, :, :]  # (batch, 50, 5)\n",
    "        # Process through LSTM\n",
    "        ego_lstm_out, _ = self.ego_encoder(ego_traj)\n",
    "        # Extract final hidden state\n",
    "        ego_features = ego_lstm_out[:, -1, :]\n",
    "        \n",
    "        # CLOSEST NEIGHBOR\n",
    "        # ---- DISTANCES TO OTHER AGENTS ----\n",
    "        ego_pos = x[:, 0, 49, :2].unsqueeze(1)  # (batch, 1, 2)\n",
    "        agent_pos = x[:, :, 49, :2]  # (batch, 50, 2)\n",
    "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
    "        dists[:, 0] = float('inf')  # mask out ego\n",
    "        \n",
    "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 3)\n",
    "        \n",
    "        # ---- ENCODE NEIGHBORS ----\n",
    "        neighbor_out_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            idx = neighbor_ids[:, i]  # (batch,)\n",
    "            neighbor_trajs = torch.stack([x[b, idx[b]] for b in range(batch_size)], dim=0)  # (batch, 50, 5)\n",
    "\n",
    "            neighbor_lstm_out, _ = self.neighbor_encoder(neighbor_trajs)  # both: (num_layers, batch, hidden_dim)\n",
    "\n",
    "            neighbor_out_list.append(neighbor_lstm_out[:, -1, :])\n",
    "\n",
    "        # ---- CONCATENATE HIDDEN AND CELL STATES ----\n",
    "        all_features = torch.cat([ego_features] + neighbor_out_list, dim=1)  # (num_layers, batch, hidden_dim * 4)\n",
    "        \n",
    "        # Process through prediction head\n",
    "        features = self.relu(self.fc1(all_features))\n",
    "        features = self.dropout(features)\n",
    "        out = self.fc2(features)\n",
    "        \n",
    "        # Reshape to (batch_size, 60, 2)\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, hidden_dim=64):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            # nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_experts)\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        logits = self.net(context)  # [batch_size, num_experts]\n",
    "        weights = F.softmax(logits, dim=-1)\n",
    "        return weights\n",
    "\n",
    "class MoEModel(nn.Module):\n",
    "    def __init__(self, expert_models, gating_input_dim, future_steps):\n",
    "        super(MoEModel, self).__init__()\n",
    "        self.expert_models = nn.ModuleList(expert_models)\n",
    "        self.gating_net = GatingNetwork(gating_input_dim, len(expert_models))\n",
    "        self.future_steps = future_steps\n",
    "        self.context_encoder = nn.LSTM(input_size=9, hidden_size=gating_input_dim, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        \"\"\"\n",
    "        input_dict:\n",
    "            - context: [batch_size, gating_input_dim] --> for gating net\n",
    "            - inputs_per_model: list of input tensors, one per model\n",
    "        Returns:\n",
    "            - [batch_size, future_steps, 2]  # future positions\n",
    "        \"\"\"\n",
    "        model_inputs = input_dict['inputs_per_model']\n",
    "        batch_size = model_inputs[0].size(0)\n",
    "        # context = input_dict['context']\n",
    "        model_input =model_inputs[-1]\n",
    "        ego_pos = model_input[:, 0, 49, :2].unsqueeze(1)  # (batch, 1, 2)\n",
    "        ego_features = model_input[:, 0, :, :]\n",
    "        agent_pos = model_input[:, :, 49, :2]  # (batch, 50, 2)\n",
    "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
    "        dists[:, 0] = float('inf')  # mask out ego\n",
    "        \n",
    "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 3)\n",
    "        \n",
    "        # ---- ENCODE NEIGHBORS ----\n",
    "        neighbor_out_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            idx = neighbor_ids[:, i]  # (batch,)\n",
    "            neighbor_trajs = torch.stack([model_input[b, idx[b]] for b in range(batch_size)], dim=0)  # (batch, 50, 5)\n",
    "        \n",
    "        ego_features[..., :4] = ego_features[..., :4] - neighbor_trajs[..., :4]\n",
    "\n",
    "        context, (hidden, cell)= self.context_encoder(ego_features)\n",
    "        # print('encoder done')\n",
    "        weights = self.gating_net(hidden[:, -1, :])  # [batch_size, num_experts]\n",
    "        # print('gating')\n",
    "        expert_preds = []\n",
    "        for i, model in enumerate(self.expert_models):\n",
    "            # print(i)\n",
    "            pred = model(model_inputs[i])  # [batch_size, future_steps, 2]\n",
    "            expert_preds.append(pred.unsqueeze(1))  # [B, 1, T, 2]\n",
    "\n",
    "        expert_preds = torch.cat(expert_preds, dim=1)  # [B, E, T, 2]\n",
    "        weights = weights.unsqueeze(-1).unsqueeze(-1)  # [B, E, 1, 1]\n",
    "\n",
    "        fused = torch.sum(expert_preds * weights, dim=1)  # [B, T, 2]\n",
    "        return fused.view(-1, 60, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_improved_model(model, train_dataloader, val_dataloader, \n",
    "                         device, criterion=nn.MSELoss(), \n",
    "                         lr=0.001, epochs=100, patience=15):\n",
    "    \"\"\"\n",
    "    Improved training function with better debugging and early stopping\n",
    "    \"\"\"\n",
    "    # Initialize optimizer with smaller learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Exponential decay scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    \n",
    "    early_stopping_patience = patience\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    \n",
    "    # Save initial state for comparison\n",
    "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_train_batches = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            x = batch.x\n",
    "            # x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "            input_dict = {\n",
    "                    \"inputs_per_model\": [\n",
    "                        # x[..., :5].reshape(-1,50,50,5),\n",
    "                        x[..., :5].reshape(-1,50,50,5),  # input for PositionModel\n",
    "                        x[..., :8].reshape(-1,50,50,8),  # input for VelocityModel\n",
    "                        x[..., :9].reshape(-1,50,50,9)  # input for AccelAngularModel\n",
    "                    ]}\n",
    "            pred = model(input_dict)\n",
    "            y_all  = batch.y.view(batch.num_graphs, 60, 4)\n",
    "            y = y_all[..., 2:4]\n",
    "            \n",
    "            # Check for NaN predictions\n",
    "            if torch.isnan(pred).any():\n",
    "                print(f\"WARNING: NaN detected in predictions during training\")\n",
    "                continue\n",
    "                \n",
    "            loss = criterion(pred, y)\n",
    "            \n",
    "            # Check if loss is valid\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
    "                continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # More conservative gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "        \n",
    "        # Skip epoch if no valid batches\n",
    "        if num_train_batches == 0:\n",
    "            print(\"WARNING: No valid training batches in this epoch\")\n",
    "            continue\n",
    "            \n",
    "        train_loss /= num_train_batches\n",
    "        \n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        val_mse = 0\n",
    "        num_val_batches = 0\n",
    "        \n",
    "        # Sample predictions for debugging\n",
    "        sample_input = None\n",
    "        sample_pred = None\n",
    "        sample_target = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_dataloader):\n",
    "                batch = batch.to(device)\n",
    "                x = batch.x\n",
    "                # x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "                input_dict = {\n",
    "                    \"inputs_per_model\": [\n",
    "                        # x[..., :5].reshape(-1,50,50,5),\n",
    "                        x[..., :5].reshape(-1,50,50,5),  # input for PositionModel\n",
    "                        x[..., :8].reshape(-1,50,50,8),  # input for VelocityModel\n",
    "                        x[..., :9].reshape(-1,50,50,9)  # input for AccelAngularModel\n",
    "                    ]}\n",
    "                \n",
    "                pred = model(input_dict)\n",
    "                y_all  = batch.y.view(batch.num_graphs, 60, 4)\n",
    "                y = y_all[..., 2:4]\n",
    "                \n",
    "                # Store sample for debugging\n",
    "                if batch_idx == 0 and sample_input is None:\n",
    "                    sample_input = batch.x[0].cpu().numpy()\n",
    "                    sample_pred = pred[0].cpu().numpy()\n",
    "                    sample_target = y[0].cpu().numpy()\n",
    "                \n",
    "                # Skip invalid predictions\n",
    "                if torch.isnan(pred).any():\n",
    "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
    "                    continue\n",
    "                    \n",
    "                batch_loss = criterion(pred, y).item()\n",
    "                val_loss += batch_loss\n",
    "                \n",
    "                # Unnormalize for real-world metrics\n",
    "                pred_unnorm = pred * batch.scale.view(-1, 1, 1)\n",
    "                y_unnorm = y * batch.scale.view(-1, 1, 1)\n",
    "                \n",
    "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
    "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
    "                \n",
    "                num_val_batches += 1\n",
    "        \n",
    "        # Skip epoch if no valid validation batches\n",
    "        if num_val_batches == 0:\n",
    "            print(\"WARNING: No valid validation batches in this epoch\")\n",
    "            continue\n",
    "            \n",
    "        val_loss /= num_val_batches\n",
    "        val_mae /= num_val_batches\n",
    "        val_mse /= num_val_batches\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print with more details\n",
    "        tqdm.tqdm.write(\n",
    "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
    "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
    "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Debug output - first 3 predictions vs targets\n",
    "        if epoch % 5 == 0:\n",
    "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
    "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
    "            \n",
    "            # Check if model weights are changing\n",
    "            if epoch > 0:\n",
    "                weight_change = False\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        initial_param = initial_state_dict[name]\n",
    "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
    "                            weight_change = True\n",
    "                            break\n",
    "                if not weight_change:\n",
    "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
    "        \n",
    "        # Relaxed improvement criterion - consider any improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), best_model)\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= early_stopping_patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
    "                break\n",
    "    \n",
    "    # Load best model before returning\n",
    "    model.load_state_dict(torch.load(best_model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def train_and_evaluate_model(model_list):\n",
    "    # Create model\n",
    "    expert_models = model_list\n",
    "    moe = MoEModel(expert_models, gating_input_dim=64, future_steps=30)\n",
    "    moe = moe.to(device)\n",
    "    \n",
    "    # Train with improved function\n",
    "    train_improved_model(\n",
    "        model=moe,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        device=device,\n",
    "        # lr = 0.007 => 8.946\n",
    "        lr=0.001,  # Lower learning rate\n",
    "        patience=20,  # More patience\n",
    "        epochs=150\n",
    "    )\n",
    "    \n",
    "    # # Evaluate\n",
    "    # moe.eval()\n",
    "    # test_mse = 0\n",
    "    # test_mse_xy = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for batch in val_dataloader:\n",
    "    #         batch = batch.to(device)\n",
    "    #         pred = moe(batch)\n",
    "    #         y_all  = batch.y.view(batch.num_graphs, 60, 4)\n",
    "    #         y = y_all[..., 2:4]\n",
    "    #         y_xy = y_all[..., 0:2]\n",
    "    #         origin = batch.origin.unsqueeze(1)\n",
    "    #         # Unnormalize\n",
    "    #         pred = pred * batch.scale.view(-1, 1, 1)\n",
    "    #         y = y * batch.scale.view(-1, 1, 1)\n",
    "    #         y_xy = y_xy * batch.scale.view(-1, 1, 1)\n",
    "            \n",
    "    #         test_mse += nn.MSELoss()(pred, y).item()\n",
    "    #         dt = 0.1  # seconds per step\n",
    "    #         pred_pos = [origin]  # list of (B, 1, 2)\n",
    "\n",
    "    #         for t in range(60):\n",
    "    #             next_pos = pred_pos[-1] + pred[:, t:t+1, :] * dt  # (B, 1, 2)\n",
    "    #             pred_pos.append(next_pos)\n",
    "\n",
    "    #         # Concatenate positions across time steps\n",
    "    #         pred_xy = torch.cat(pred_pos[1:], dim=1)\n",
    "    #         test_mse_xy +=nn.MSELoss()(pred_xy, y_xy).item()\n",
    "    # test_mse /= len(val_dataloader)\n",
    "    # test_mse_xy /= len(val_dataloader)\n",
    "    # print(f\"Val MSE: {test_mse:.4f}\")\n",
    "\n",
    "    \n",
    "    return moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, laoder):\n",
    "    model.eval()\n",
    "    test_mse = 0\n",
    "    test_mse_xy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in laoder:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y_all  = batch.y.view(batch.num_graphs, 60, 4)\n",
    "            y = y_all[..., 2:4]\n",
    "            y_xy = y_all[..., 0:2]\n",
    "            origin = batch.origin.unsqueeze(1)\n",
    "            # Unnormalize\n",
    "            pred = pred * batch.scale.view(-1, 1, 1)\n",
    "            y = y * batch.scale.view(-1, 1, 1)\n",
    "            y_xy = y_xy * batch.scale.view(-1, 1, 1)\n",
    "            \n",
    "            test_mse += nn.MSELoss()(pred, y).item()\n",
    "            dt = 0.1  # seconds per step\n",
    "            pred_pos = [0]  # list of (B, 1, 2)\n",
    "\n",
    "            for t in range(60):\n",
    "                next_pos = pred_pos[-1] + pred[:, t:t+1, :] * dt  # (B, 1, 2)\n",
    "                pred_pos.append(next_pos)\n",
    "\n",
    "            # Concatenate positions across time steps\n",
    "            pred_xy = torch.cat(pred_pos[1:], dim=1)\n",
    "            # print(test_mse)\n",
    "            test_mse_xy += nn.MSELoss()(pred_xy, y_xy).item()\n",
    "            # print(test_mse_xy)\n",
    "    test_mse /= len(val_dataloader)\n",
    "    test_mse_xy /= len(val_dataloader)\n",
    "    print(f\"Val MSE: {test_mse:.4f}\")\n",
    "    print(f\"Val MSE: {test_mse_xy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/150 [00:00<?, ?epoch/s]/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_61751/1146201446.py:51: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future[..., :2] = future[..., :2] - origin\n",
      "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_61751/1146201446.py:23: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future[..., :2] = future[..., :2] @ R\n",
      "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_61751/1146201446.py:24: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future[..., 2:4] = future[..., 2:4] @ R\n",
      "Epoch:   1%|          | 1/150 [00:28<1:10:29, 28.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR 0.000950 | Train MSE 0.1724 | Val MSE 0.0900 | Val MAE 1.4060 | Val MSE 4.4104\n",
      "Sample pred first 3 steps: [[-0.01059493 -0.0205432 ]\n",
      " [-0.01287978 -0.01940733]\n",
      " [-0.01416496 -0.01945248]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n",
      "Validation improved: inf -> 0.090008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1%|▏         | 2/150 [00:56<1:09:01, 27.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | LR 0.000902 | Train MSE 0.0980 | Val MSE 0.0750 | Val MAE 1.2175 | Val MSE 3.6774\n",
      "Validation improved: 0.090008 -> 0.075048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 3/150 [01:23<1:07:59, 27.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | LR 0.000857 | Train MSE 0.0811 | Val MSE 0.0724 | Val MAE 1.1601 | Val MSE 3.5458\n",
      "Validation improved: 0.075048 -> 0.072364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 4/150 [01:51<1:07:22, 27.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | LR 0.000815 | Train MSE 0.0778 | Val MSE 0.0617 | Val MAE 1.1120 | Val MSE 3.0236\n",
      "Validation improved: 0.072364 -> 0.061706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 5/150 [02:19<1:07:08, 27.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | LR 0.000774 | Train MSE 0.0819 | Val MSE 0.0586 | Val MAE 1.0650 | Val MSE 2.8716\n",
      "Validation improved: 0.061706 -> 0.058603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 6/150 [02:47<1:06:48, 27.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | LR 0.000735 | Train MSE 0.0641 | Val MSE 0.0619 | Val MAE 1.0373 | Val MSE 3.0316\n",
      "Sample pred first 3 steps: [[-0.03051857 -0.01122168]\n",
      " [-0.02775079 -0.01010021]\n",
      " [-0.02435523 -0.0092591 ]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▍         | 7/150 [03:14<1:06:22, 27.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | LR 0.000698 | Train MSE 0.0620 | Val MSE 0.0575 | Val MAE 1.0385 | Val MSE 2.8188\n",
      "Validation improved: 0.058603 -> 0.057526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 8/150 [03:42<1:06:03, 27.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | LR 0.000663 | Train MSE 0.0596 | Val MSE 0.0561 | Val MAE 1.0154 | Val MSE 2.7507\n",
      "Validation improved: 0.057526 -> 0.056136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 9/150 [04:11<1:05:50, 28.01s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | LR 0.000630 | Train MSE 0.0598 | Val MSE 0.0505 | Val MAE 0.9620 | Val MSE 2.4734\n",
      "Validation improved: 0.056136 -> 0.050479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 10/150 [04:39<1:05:36, 28.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | LR 0.000599 | Train MSE 0.0568 | Val MSE 0.0509 | Val MAE 0.9587 | Val MSE 2.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 11/150 [05:07<1:05:03, 28.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | LR 0.000569 | Train MSE 0.0616 | Val MSE 0.0711 | Val MAE 1.0172 | Val MSE 3.4845\n",
      "Sample pred first 3 steps: [[-0.02117983  0.00184315]\n",
      " [-0.01958773  0.00051857]\n",
      " [-0.01797159 -0.00179574]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 12/150 [05:38<1:06:22, 28.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | LR 0.000540 | Train MSE 0.0606 | Val MSE 0.0600 | Val MAE 1.0009 | Val MSE 2.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   9%|▊         | 13/150 [06:08<1:06:47, 29.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | LR 0.000513 | Train MSE 0.0564 | Val MSE 0.0493 | Val MAE 0.9568 | Val MSE 2.4156\n",
      "Validation improved: 0.050479 -> 0.049299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   9%|▉         | 14/150 [06:38<1:07:11, 29.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | LR 0.000488 | Train MSE 0.0549 | Val MSE 0.0568 | Val MAE 0.9722 | Val MSE 2.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 15/150 [07:14<1:10:37, 31.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | LR 0.000463 | Train MSE 0.0543 | Val MSE 0.0563 | Val MAE 0.9728 | Val MSE 2.7565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  11%|█         | 16/150 [07:47<1:11:16, 31.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | LR 0.000440 | Train MSE 0.0572 | Val MSE 0.0530 | Val MAE 0.9402 | Val MSE 2.5974\n",
      "Sample pred first 3 steps: [[0.00641353 0.02593149]\n",
      " [0.00584396 0.02451914]\n",
      " [0.00558462 0.02436241]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  11%|█▏        | 17/150 [08:19<1:10:44, 31.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | LR 0.000418 | Train MSE 0.0536 | Val MSE 0.0530 | Val MAE 0.9381 | Val MSE 2.5962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 18/150 [08:53<1:11:40, 32.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | LR 0.000397 | Train MSE 0.0504 | Val MSE 0.0519 | Val MAE 0.9485 | Val MSE 2.5454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 19/150 [09:26<1:11:14, 32.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | LR 0.000377 | Train MSE 0.0515 | Val MSE 0.0519 | Val MAE 0.9406 | Val MSE 2.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 20/150 [09:59<1:11:05, 32.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | LR 0.000358 | Train MSE 0.0497 | Val MSE 0.0522 | Val MAE 0.9281 | Val MSE 2.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 21/150 [10:33<1:11:22, 33.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | LR 0.000341 | Train MSE 0.0512 | Val MSE 0.0493 | Val MAE 0.9207 | Val MSE 2.4181\n",
      "Sample pred first 3 steps: [[0.00877132 0.0434375 ]\n",
      " [0.00695176 0.0412857 ]\n",
      " [0.00529175 0.0409074 ]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▍        | 22/150 [11:07<1:11:32, 33.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | LR 0.000324 | Train MSE 0.0483 | Val MSE 0.0485 | Val MAE 0.9129 | Val MSE 2.3757\n",
      "Validation improved: 0.049299 -> 0.048483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 23/150 [11:41<1:10:54, 33.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | LR 0.000307 | Train MSE 0.0488 | Val MSE 0.0486 | Val MAE 0.9100 | Val MSE 2.3813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 24/150 [12:15<1:10:59, 33.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | LR 0.000292 | Train MSE 0.0469 | Val MSE 0.0477 | Val MAE 0.8998 | Val MSE 2.3361\n",
      "Validation improved: 0.048483 -> 0.047676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 25/150 [12:48<1:09:56, 33.57s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | LR 0.000277 | Train MSE 0.0492 | Val MSE 0.0528 | Val MAE 0.9232 | Val MSE 2.5878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  17%|█▋        | 26/150 [13:22<1:09:25, 33.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | LR 0.000264 | Train MSE 0.0464 | Val MSE 0.0507 | Val MAE 0.9070 | Val MSE 2.4842\n",
      "Sample pred first 3 steps: [[0.02188403 0.0196551 ]\n",
      " [0.0209751  0.01736747]\n",
      " [0.01835225 0.01692602]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 27/150 [13:56<1:09:09, 33.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | LR 0.000250 | Train MSE 0.0476 | Val MSE 0.0518 | Val MAE 0.9200 | Val MSE 2.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  19%|█▊        | 28/150 [14:30<1:08:37, 33.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | LR 0.000238 | Train MSE 0.0461 | Val MSE 0.0517 | Val MAE 0.9172 | Val MSE 2.5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  19%|█▉        | 29/150 [15:04<1:08:04, 33.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | LR 0.000226 | Train MSE 0.0455 | Val MSE 0.0506 | Val MAE 0.9019 | Val MSE 2.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 30/150 [15:37<1:07:14, 33.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | LR 0.000215 | Train MSE 0.0468 | Val MSE 0.0535 | Val MAE 0.9371 | Val MSE 2.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  21%|██        | 31/150 [16:10<1:06:21, 33.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | LR 0.000204 | Train MSE 0.0450 | Val MSE 0.0502 | Val MAE 0.9090 | Val MSE 2.4622\n",
      "Sample pred first 3 steps: [[0.02345403 0.0513161 ]\n",
      " [0.02187377 0.04915054]\n",
      " [0.01950306 0.04672467]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  21%|██▏       | 32/150 [16:44<1:06:05, 33.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | LR 0.000194 | Train MSE 0.0453 | Val MSE 0.0494 | Val MAE 0.8971 | Val MSE 2.4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 33/150 [17:17<1:05:11, 33.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | LR 0.000184 | Train MSE 0.0456 | Val MSE 0.0489 | Val MAE 0.8878 | Val MSE 2.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  23%|██▎       | 34/150 [17:51<1:04:58, 33.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | LR 0.000175 | Train MSE 0.0443 | Val MSE 0.0490 | Val MAE 0.8981 | Val MSE 2.4009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  23%|██▎       | 35/150 [18:24<1:04:17, 33.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | LR 0.000166 | Train MSE 0.0435 | Val MSE 0.0484 | Val MAE 0.8719 | Val MSE 2.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 36/150 [18:58<1:03:43, 33.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | LR 0.000158 | Train MSE 0.0437 | Val MSE 0.0500 | Val MAE 0.8937 | Val MSE 2.4496\n",
      "Sample pred first 3 steps: [[0.00356904 0.03973006]\n",
      " [0.00322617 0.03677312]\n",
      " [0.00273846 0.03568399]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▍       | 37/150 [19:31<1:02:58, 33.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | LR 0.000150 | Train MSE 0.0430 | Val MSE 0.0501 | Val MAE 0.8924 | Val MSE 2.4528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 38/150 [20:04<1:02:05, 33.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | LR 0.000142 | Train MSE 0.0466 | Val MSE 0.0480 | Val MAE 0.8837 | Val MSE 2.3496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 39/150 [20:37<1:01:20, 33.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | LR 0.000135 | Train MSE 0.0425 | Val MSE 0.0482 | Val MAE 0.8877 | Val MSE 2.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 40/150 [21:10<1:00:34, 33.04s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | LR 0.000129 | Train MSE 0.0426 | Val MSE 0.0495 | Val MAE 0.8874 | Val MSE 2.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 41/150 [21:43<1:00:09, 33.11s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | LR 0.000122 | Train MSE 0.0428 | Val MSE 0.0489 | Val MAE 0.8817 | Val MSE 2.3943\n",
      "Sample pred first 3 steps: [[-0.00234975  0.0416768 ]\n",
      " [-0.00169034  0.03899324]\n",
      " [-0.00185749  0.03612714]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 42/150 [22:17<59:54, 33.28s/epoch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | LR 0.000116 | Train MSE 0.0426 | Val MSE 0.0498 | Val MAE 0.8959 | Val MSE 2.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  29%|██▊       | 43/150 [22:50<59:27, 33.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | LR 0.000110 | Train MSE 0.0419 | Val MSE 0.0485 | Val MAE 0.8866 | Val MSE 2.3752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  29%|██▊       | 43/150 [23:24<58:13, 32.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | LR 0.000105 | Train MSE 0.0431 | Val MSE 0.0486 | Val MAE 0.8874 | Val MSE 2.3828\n",
      "Early stopping after 44 epochs without improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MoEModel(\n",
       "  (expert_models): ModuleList(\n",
       "    (0): VelocityModel(\n",
       "      (ego_encoder): LSTM(5, 512, batch_first=True)\n",
       "      (neighbor_encoder): LSTM(5, 512, batch_first=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=1024, out_features=120, bias=True)\n",
       "    )\n",
       "    (1): AccelearationModel(\n",
       "      (ego_encoder): LSTM(8, 512, batch_first=True)\n",
       "      (neighbor_encoder): LSTM(8, 512, batch_first=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=1024, out_features=120, bias=True)\n",
       "    )\n",
       "    (2): AngularAccelerationModel(\n",
       "      (ego_encoder): LSTM(9, 512, batch_first=True)\n",
       "      (neighbor_encoder): LSTM(9, 512, batch_first=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=1024, out_features=120, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (gating_net): GatingNetwork(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=64, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (context_encoder): LSTM(9, 64, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate_model(expert_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_n = \"best_model_xy.pt\"\n",
    "velocity_model_n = 'best_model0_retry.pt'\n",
    "acceleration_model_n = 'best_model0_feat_eng.pt'\n",
    "angular_model_n = 'best_model0_feat_eng_add_ang_acc.pt'\n",
    "\n",
    "\n",
    "simple_model2 = torch.load(simple_model_n)\n",
    "simple_model = SimpleLSTM().to(device)\n",
    "simple_model.load_state_dict(simple_model2)\n",
    "\n",
    "velocity_model2 = torch.load(velocity_model_n)\n",
    "velocity_model = VelocityModel().to(device)\n",
    "velocity_model.load_state_dict(velocity_model2)\n",
    "\n",
    "acceleration_model2 = torch.load(acceleration_model_n)\n",
    "acceleration_model = AccelearationModel().to(device)\n",
    "acceleration_model.load_state_dict(acceleration_model2)\n",
    "\n",
    "angular_model2 = torch.load(angular_model_n)\n",
    "angular_model = AngularAccelerationModel().to(device)\n",
    "angular_model.load_state_dict(angular_model2)\n",
    "\n",
    "\n",
    "expert_models = [\n",
    "                #    simple_model,\n",
    "                   velocity_model,\n",
    "                   acceleration_model,\n",
    "                    angular_model\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
