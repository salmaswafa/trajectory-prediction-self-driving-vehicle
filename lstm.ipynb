{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of basic model that should work\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=6, hidden_dim=128, output_dim=60*2):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Add multi-layer prediction head for better results\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        x = x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "        x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "        # Process through LSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        \n",
        "        # Extract final hidden state\n",
        "        features = lstm_out[:, -1, :]\n",
        "        \n",
        "        # Process through prediction head\n",
        "        features = self.relu(self.fc1(features))\n",
        "        features = self.dropout(features)\n",
        "        out = self.fc2(features)\n",
        "        \n",
        "        # Reshape to (batch_size, 60, 2)\n",
        "        return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_49283/3713195397.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_49283/3713195397.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future - origin\n",
            "Epoch:   1%|          | 1/100 [00:07<12:51,  7.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.000475 | Train MSE 2.0975 | Val MSE 0.4853 | Val MAE 2.6188 | Val MSE 23.7802\n",
            "Sample pred first 3 steps: [[ 0.01209358 -0.01262153]\n",
            " [ 0.01291927  0.04639293]\n",
            " [ 0.02713237 -0.03327122]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: inf -> 0.485311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 2/100 [00:13<10:31,  6.45s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.000451 | Train MSE 0.5095 | Val MSE 0.3435 | Val MAE 2.2203 | Val MSE 16.8302\n",
            "Validation improved: 0.485311 -> 0.343474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 3/100 [00:18<09:40,  5.99s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.000429 | Train MSE 0.4210 | Val MSE 0.2989 | Val MAE 2.1143 | Val MSE 14.6454\n",
            "Validation improved: 0.343474 -> 0.298887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 4/100 [00:24<09:12,  5.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.000407 | Train MSE 0.3824 | Val MSE 0.2871 | Val MAE 1.9051 | Val MSE 14.0668\n",
            "Validation improved: 0.298887 -> 0.287077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [00:29<08:55,  5.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.000387 | Train MSE 0.3542 | Val MSE 0.2838 | Val MAE 2.0263 | Val MSE 13.9060\n",
            "Validation improved: 0.287077 -> 0.283797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [00:34<08:55,  5.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.000368 | Train MSE 0.3319 | Val MSE 0.2854 | Val MAE 2.0671 | Val MSE 13.9865\n",
            "Sample pred first 3 steps: [[-0.00465532 -0.01156954]\n",
            " [-0.01975883  0.00478906]\n",
            " [-0.00668545  0.02861509]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 7/100 [00:40<08:38,  5.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.000349 | Train MSE 0.3255 | Val MSE 0.2554 | Val MAE 1.8039 | Val MSE 12.5168\n",
            "Validation improved: 0.283797 -> 0.255445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 8/100 [00:46<08:27,  5.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.000332 | Train MSE 0.3156 | Val MSE 0.2534 | Val MAE 1.8064 | Val MSE 12.4152\n",
            "Validation improved: 0.255445 -> 0.253372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 9/100 [00:51<08:18,  5.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.000315 | Train MSE 0.3074 | Val MSE 0.2620 | Val MAE 1.8302 | Val MSE 12.8376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 10/100 [00:56<08:07,  5.41s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.000299 | Train MSE 0.3019 | Val MSE 0.2558 | Val MAE 1.8044 | Val MSE 12.5354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 11/100 [01:02<08:13,  5.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.000284 | Train MSE 0.2951 | Val MSE 0.2440 | Val MAE 1.7906 | Val MSE 11.9561\n",
            "Sample pred first 3 steps: [[-0.00753415 -0.0026619 ]\n",
            " [-0.00682133  0.00198884]\n",
            " [-0.01065744 -0.00041776]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.253372 -> 0.244002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 12/100 [01:08<08:19,  5.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.000270 | Train MSE 0.2853 | Val MSE 0.2553 | Val MAE 1.9067 | Val MSE 12.5088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 13/100 [01:14<08:14,  5.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.000257 | Train MSE 0.2856 | Val MSE 0.2513 | Val MAE 1.8619 | Val MSE 12.3149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 14/100 [01:19<08:03,  5.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.000244 | Train MSE 0.2873 | Val MSE 0.2210 | Val MAE 1.6777 | Val MSE 10.8309\n",
            "Validation improved: 0.244002 -> 0.221039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 15/100 [01:25<07:53,  5.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.000232 | Train MSE 0.2769 | Val MSE 0.2263 | Val MAE 1.7082 | Val MSE 11.0878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 16/100 [01:30<07:43,  5.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.000220 | Train MSE 0.2749 | Val MSE 0.2322 | Val MAE 1.6776 | Val MSE 11.3776\n",
            "Sample pred first 3 steps: [[-0.00194155  0.00254375]\n",
            " [-0.00441842  0.00250216]\n",
            " [-0.00413484  0.00437956]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 17/100 [01:36<07:35,  5.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.000209 | Train MSE 0.2718 | Val MSE 0.2226 | Val MAE 1.5841 | Val MSE 10.9076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 18/100 [01:41<07:25,  5.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.000199 | Train MSE 0.2703 | Val MSE 0.2258 | Val MAE 1.6784 | Val MSE 11.0662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 19/100 [01:46<07:17,  5.40s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.000189 | Train MSE 0.2644 | Val MSE 0.2196 | Val MAE 1.6222 | Val MSE 10.7622\n",
            "Validation improved: 0.221039 -> 0.219638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 20/100 [01:52<07:15,  5.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.000179 | Train MSE 0.2683 | Val MSE 0.2165 | Val MAE 1.6054 | Val MSE 10.6061\n",
            "Validation improved: 0.219638 -> 0.216452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 21/100 [01:57<07:12,  5.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.000170 | Train MSE 0.2633 | Val MSE 0.2193 | Val MAE 1.6683 | Val MSE 10.7443\n",
            "Sample pred first 3 steps: [[-0.00059889  0.00083085]\n",
            " [-0.00028754  0.00123013]\n",
            " [-0.00060217  0.00011652]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 22/100 [02:04<07:34,  5.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.000162 | Train MSE 0.2626 | Val MSE 0.2193 | Val MAE 1.5854 | Val MSE 10.7438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 23/100 [02:09<07:19,  5.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.000154 | Train MSE 0.2598 | Val MSE 0.2391 | Val MAE 1.7648 | Val MSE 11.7148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 24/100 [02:15<07:08,  5.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.000146 | Train MSE 0.2572 | Val MSE 0.2162 | Val MAE 1.6073 | Val MSE 10.5962\n",
            "Validation improved: 0.216452 -> 0.216249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 25/100 [02:20<07:02,  5.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.000139 | Train MSE 0.2565 | Val MSE 0.2206 | Val MAE 1.6793 | Val MSE 10.8109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [02:26<06:53,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.000132 | Train MSE 0.2541 | Val MSE 0.2159 | Val MAE 1.5720 | Val MSE 10.5777\n",
            "Sample pred first 3 steps: [[0.00028644 0.00119208]\n",
            " [0.00076822 0.00099   ]\n",
            " [0.00202987 0.00042371]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.216249 -> 0.215872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 27/100 [02:31<06:47,  5.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.000125 | Train MSE 0.2563 | Val MSE 0.2145 | Val MAE 1.6103 | Val MSE 10.5121\n",
            "Validation improved: 0.215872 -> 0.214532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 28/100 [02:37<06:46,  5.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.000119 | Train MSE 0.2513 | Val MSE 0.2140 | Val MAE 1.6081 | Val MSE 10.4842\n",
            "Validation improved: 0.214532 -> 0.213964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 29/100 [02:43<06:37,  5.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.000113 | Train MSE 0.2528 | Val MSE 0.2090 | Val MAE 1.5658 | Val MSE 10.2422\n",
            "Validation improved: 0.213964 -> 0.209025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 30/100 [02:48<06:30,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.000107 | Train MSE 0.2482 | Val MSE 0.2098 | Val MAE 1.6054 | Val MSE 10.2795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 31/100 [02:54<06:26,  5.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.000102 | Train MSE 0.2485 | Val MSE 0.2044 | Val MAE 1.5448 | Val MSE 10.0140\n",
            "Sample pred first 3 steps: [[ 2.1166606e-03  6.9588609e-04]\n",
            " [ 5.0095120e-03  6.5138564e-05]\n",
            " [ 9.0878084e-03 -1.1274619e-03]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.209025 -> 0.204367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 32/100 [02:59<06:19,  5.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.000097 | Train MSE 0.2462 | Val MSE 0.2063 | Val MAE 1.5677 | Val MSE 10.1089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 33/100 [03:06<06:31,  5.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.000092 | Train MSE 0.2421 | Val MSE 0.2101 | Val MAE 1.5570 | Val MSE 10.2942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 34/100 [03:11<06:19,  5.75s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.000087 | Train MSE 0.2416 | Val MSE 0.2077 | Val MAE 1.5676 | Val MSE 10.1783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 35/100 [03:17<06:08,  5.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.000083 | Train MSE 0.2433 | Val MSE 0.2102 | Val MAE 1.5446 | Val MSE 10.3013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 36/100 [03:22<05:59,  5.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.000079 | Train MSE 0.2421 | Val MSE 0.1985 | Val MAE 1.4862 | Val MSE 9.7272\n",
            "Sample pred first 3 steps: [[-0.00046698  0.0020055 ]\n",
            " [-0.00057977  0.00441941]\n",
            " [-0.00014407  0.00578259]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.204367 -> 0.198515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 37/100 [03:28<05:51,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.000075 | Train MSE 0.2417 | Val MSE 0.2002 | Val MAE 1.4902 | Val MSE 9.8074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 38/100 [03:34<05:46,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.000071 | Train MSE 0.2394 | Val MSE 0.1974 | Val MAE 1.5220 | Val MSE 9.6724\n",
            "Validation improved: 0.198515 -> 0.197395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 39/100 [03:39<05:40,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.000068 | Train MSE 0.2416 | Val MSE 0.1990 | Val MAE 1.5117 | Val MSE 9.7517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 40/100 [03:45<05:32,  5.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.000064 | Train MSE 0.2392 | Val MSE 0.1987 | Val MAE 1.4672 | Val MSE 9.7382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 41/100 [03:50<05:26,  5.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.000061 | Train MSE 0.2364 | Val MSE 0.1998 | Val MAE 1.4836 | Val MSE 9.7878\n",
            "Sample pred first 3 steps: [[-3.4020282e-05  1.3633168e-03]\n",
            " [ 3.6623701e-04  2.0969920e-03]\n",
            " [ 4.1724462e-04  2.6727454e-03]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 42/100 [03:56<05:21,  5.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.000058 | Train MSE 0.2388 | Val MSE 0.1956 | Val MAE 1.4668 | Val MSE 9.5848\n",
            "Validation improved: 0.197395 -> 0.195608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 43/100 [04:02<05:23,  5.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.000055 | Train MSE 0.2348 | Val MSE 0.2005 | Val MAE 1.5226 | Val MSE 9.8236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 44/100 [04:07<05:20,  5.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.000052 | Train MSE 0.2354 | Val MSE 0.1974 | Val MAE 1.4877 | Val MSE 9.6711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 45/100 [04:13<05:11,  5.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.000050 | Train MSE 0.2365 | Val MSE 0.1979 | Val MAE 1.5215 | Val MSE 9.6991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 46/100 [04:19<05:03,  5.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.000047 | Train MSE 0.2351 | Val MSE 0.1951 | Val MAE 1.4449 | Val MSE 9.5575\n",
            "Sample pred first 3 steps: [[ 0.00156909 -0.00062859]\n",
            " [ 0.00268569 -0.00034138]\n",
            " [ 0.00342022 -0.00055727]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.195608 -> 0.195051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 47/100 [04:24<04:58,  5.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.000045 | Train MSE 0.2341 | Val MSE 0.1968 | Val MAE 1.4977 | Val MSE 9.6426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 48/100 [04:30<04:50,  5.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.000043 | Train MSE 0.2346 | Val MSE 0.1976 | Val MAE 1.4750 | Val MSE 9.6827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 49/100 [04:35<04:46,  5.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.000040 | Train MSE 0.2319 | Val MSE 0.1933 | Val MAE 1.4550 | Val MSE 9.4723\n",
            "Validation improved: 0.195051 -> 0.193312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 50/100 [04:41<04:41,  5.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.000038 | Train MSE 0.2320 | Val MSE 0.1948 | Val MAE 1.4668 | Val MSE 9.5434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 51/100 [04:46<04:33,  5.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.000037 | Train MSE 0.2345 | Val MSE 0.2008 | Val MAE 1.5301 | Val MSE 9.8394\n",
            "Sample pred first 3 steps: [[0.00014459 0.00090863]\n",
            " [0.0001398  0.00145131]\n",
            " [0.00012538 0.00116522]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 52/100 [04:52<04:34,  5.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.000035 | Train MSE 0.2348 | Val MSE 0.1930 | Val MAE 1.4355 | Val MSE 9.4583\n",
            "Validation improved: 0.193312 -> 0.193026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 53/100 [04:59<04:37,  5.91s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.000033 | Train MSE 0.2319 | Val MSE 0.1939 | Val MAE 1.4651 | Val MSE 9.5018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  54%|█████▍    | 54/100 [05:06<04:43,  6.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | LR 0.000031 | Train MSE 0.2319 | Val MSE 0.1904 | Val MAE 1.4462 | Val MSE 9.3290\n",
            "Validation improved: 0.193026 -> 0.190388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▌    | 55/100 [05:12<04:43,  6.31s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | LR 0.000030 | Train MSE 0.2302 | Val MSE 0.1923 | Val MAE 1.4423 | Val MSE 9.4249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  56%|█████▌    | 56/100 [05:19<04:41,  6.41s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | LR 0.000028 | Train MSE 0.2319 | Val MSE 0.1962 | Val MAE 1.5107 | Val MSE 9.6139\n",
            "Sample pred first 3 steps: [[ 0.00014961  0.00124288]\n",
            " [-0.00066874  0.0026401 ]\n",
            " [-0.00137849  0.00336262]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 57/100 [05:25<04:35,  6.41s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | LR 0.000027 | Train MSE 0.2308 | Val MSE 0.1931 | Val MAE 1.4254 | Val MSE 9.4617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  58%|█████▊    | 58/100 [05:31<04:20,  6.20s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | LR 0.000026 | Train MSE 0.2348 | Val MSE 0.1939 | Val MAE 1.4707 | Val MSE 9.5012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▉    | 59/100 [05:37<04:12,  6.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | LR 0.000024 | Train MSE 0.2330 | Val MSE 0.1964 | Val MAE 1.4814 | Val MSE 9.6233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  60%|██████    | 60/100 [05:42<03:56,  5.91s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | LR 0.000023 | Train MSE 0.2296 | Val MSE 0.1942 | Val MAE 1.4488 | Val MSE 9.5158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████    | 61/100 [05:48<03:46,  5.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | LR 0.000022 | Train MSE 0.2312 | Val MSE 0.1932 | Val MAE 1.4495 | Val MSE 9.4668\n",
            "Sample pred first 3 steps: [[0.00052276 0.00063275]\n",
            " [0.00115241 0.00145085]\n",
            " [0.00142232 0.00218098]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  62%|██████▏   | 62/100 [05:54<03:42,  5.86s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | LR 0.000021 | Train MSE 0.2313 | Val MSE 0.1931 | Val MAE 1.4603 | Val MSE 9.4628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 63/100 [05:59<03:32,  5.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | LR 0.000020 | Train MSE 0.2303 | Val MSE 0.1944 | Val MAE 1.4577 | Val MSE 9.5245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  64%|██████▍   | 64/100 [06:06<03:32,  5.89s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | LR 0.000019 | Train MSE 0.2292 | Val MSE 0.1957 | Val MAE 1.4580 | Val MSE 9.5909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 65/100 [06:11<03:20,  5.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | LR 0.000018 | Train MSE 0.2261 | Val MSE 0.1935 | Val MAE 1.4622 | Val MSE 9.4806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  66%|██████▌   | 66/100 [06:17<03:21,  5.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | LR 0.000017 | Train MSE 0.2301 | Val MSE 0.1904 | Val MAE 1.4238 | Val MSE 9.3292\n",
            "Sample pred first 3 steps: [[0.00022188 0.00021891]\n",
            " [0.00082344 0.00117678]\n",
            " [0.00095497 0.0018518 ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  67%|██████▋   | 67/100 [06:24<03:23,  6.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | LR 0.000016 | Train MSE 0.2282 | Val MSE 0.1923 | Val MAE 1.4367 | Val MSE 9.4205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  68%|██████▊   | 68/100 [06:30<03:15,  6.10s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | LR 0.000015 | Train MSE 0.2287 | Val MSE 0.1910 | Val MAE 1.4416 | Val MSE 9.3587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  69%|██████▉   | 69/100 [06:35<03:00,  5.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 068 | LR 0.000015 | Train MSE 0.2293 | Val MSE 0.1911 | Val MAE 1.4406 | Val MSE 9.3632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  70%|███████   | 70/100 [06:40<02:48,  5.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 069 | LR 0.000014 | Train MSE 0.2291 | Val MSE 0.1902 | Val MAE 1.4228 | Val MSE 9.3192\n",
            "Validation improved: 0.190388 -> 0.190187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  71%|███████   | 71/100 [06:46<02:47,  5.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070 | LR 0.000013 | Train MSE 0.2305 | Val MSE 0.1909 | Val MAE 1.4486 | Val MSE 9.3533\n",
            "Sample pred first 3 steps: [[ 1.0117429e-03 -2.9377104e-04]\n",
            " [ 2.3042827e-03 -2.6410166e-04]\n",
            " [ 3.4879798e-03 -1.2179837e-05]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  72%|███████▏  | 72/100 [06:52<02:36,  5.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 071 | LR 0.000012 | Train MSE 0.2307 | Val MSE 0.1903 | Val MAE 1.4425 | Val MSE 9.3270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  73%|███████▎  | 73/100 [06:57<02:27,  5.47s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 072 | LR 0.000012 | Train MSE 0.2281 | Val MSE 0.1898 | Val MAE 1.4353 | Val MSE 9.3016\n",
            "Validation improved: 0.190187 -> 0.189829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  74%|███████▍  | 74/100 [07:03<02:25,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 073 | LR 0.000011 | Train MSE 0.2288 | Val MSE 0.1892 | Val MAE 1.4159 | Val MSE 9.2710\n",
            "Validation improved: 0.189829 -> 0.189205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  75%|███████▌  | 75/100 [07:08<02:20,  5.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 074 | LR 0.000011 | Train MSE 0.2284 | Val MSE 0.1898 | Val MAE 1.4308 | Val MSE 9.3011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  76%|███████▌  | 76/100 [07:14<02:11,  5.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 075 | LR 0.000010 | Train MSE 0.2306 | Val MSE 0.1911 | Val MAE 1.4381 | Val MSE 9.3623\n",
            "Sample pred first 3 steps: [[ 0.00021788  0.00051399]\n",
            " [ 0.00014078  0.0006593 ]\n",
            " [-0.00010479  0.00079909]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  77%|███████▋  | 77/100 [07:19<02:04,  5.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 076 | LR 0.000010 | Train MSE 0.2289 | Val MSE 0.1906 | Val MAE 1.4292 | Val MSE 9.3384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  78%|███████▊  | 78/100 [07:24<01:57,  5.35s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 077 | LR 0.000009 | Train MSE 0.2275 | Val MSE 0.1893 | Val MAE 1.4198 | Val MSE 9.2768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  79%|███████▉  | 79/100 [07:29<01:50,  5.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 078 | LR 0.000009 | Train MSE 0.2290 | Val MSE 0.1900 | Val MAE 1.4205 | Val MSE 9.3108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  80%|████████  | 80/100 [07:34<01:44,  5.22s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 079 | LR 0.000008 | Train MSE 0.2278 | Val MSE 0.1891 | Val MAE 1.4298 | Val MSE 9.2661\n",
            "Validation improved: 0.189205 -> 0.189104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  81%|████████  | 81/100 [07:40<01:39,  5.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080 | LR 0.000008 | Train MSE 0.2305 | Val MSE 0.1889 | Val MAE 1.4110 | Val MSE 9.2552\n",
            "Sample pred first 3 steps: [[0.00039363 0.00011941]\n",
            " [0.00083877 0.00046721]\n",
            " [0.00132791 0.00084169]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.189104 -> 0.188882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  82%|████████▏ | 82/100 [07:45<01:35,  5.31s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 081 | LR 0.000007 | Train MSE 0.2268 | Val MSE 0.1893 | Val MAE 1.4237 | Val MSE 9.2777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  83%|████████▎ | 83/100 [07:50<01:29,  5.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 082 | LR 0.000007 | Train MSE 0.2285 | Val MSE 0.1907 | Val MAE 1.4355 | Val MSE 9.3441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  84%|████████▍ | 84/100 [07:55<01:23,  5.21s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 083 | LR 0.000007 | Train MSE 0.2284 | Val MSE 0.1902 | Val MAE 1.4181 | Val MSE 9.3220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  85%|████████▌ | 85/100 [08:01<01:19,  5.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 084 | LR 0.000006 | Train MSE 0.2270 | Val MSE 0.1890 | Val MAE 1.4040 | Val MSE 9.2617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  86%|████████▌ | 86/100 [08:06<01:15,  5.37s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 085 | LR 0.000006 | Train MSE 0.2277 | Val MSE 0.1894 | Val MAE 1.4119 | Val MSE 9.2826\n",
            "Sample pred first 3 steps: [[0.00089275 0.00020996]\n",
            " [0.00140089 0.0002802 ]\n",
            " [0.001843   0.00043372]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  87%|████████▋ | 87/100 [08:12<01:09,  5.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 086 | LR 0.000006 | Train MSE 0.2277 | Val MSE 0.1894 | Val MAE 1.4231 | Val MSE 9.2823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  88%|████████▊ | 88/100 [08:17<01:03,  5.32s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 087 | LR 0.000005 | Train MSE 0.2262 | Val MSE 0.1895 | Val MAE 1.4267 | Val MSE 9.2860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  89%|████████▉ | 89/100 [08:22<00:58,  5.32s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 088 | LR 0.000005 | Train MSE 0.2252 | Val MSE 0.1904 | Val MAE 1.4262 | Val MSE 9.3310\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  90%|█████████ | 90/100 [08:27<00:52,  5.25s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 089 | LR 0.000005 | Train MSE 0.2273 | Val MSE 0.1885 | Val MAE 1.4067 | Val MSE 9.2364\n",
            "Validation improved: 0.188882 -> 0.188499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  91%|█████████ | 91/100 [08:32<00:47,  5.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090 | LR 0.000005 | Train MSE 0.2268 | Val MSE 0.1896 | Val MAE 1.4193 | Val MSE 9.2906\n",
            "Sample pred first 3 steps: [[0.00051478 0.00018548]\n",
            " [0.00122563 0.00048334]\n",
            " [0.00194724 0.00077321]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  92%|█████████▏| 92/100 [08:38<00:41,  5.21s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 091 | LR 0.000004 | Train MSE 0.2299 | Val MSE 0.1894 | Val MAE 1.4148 | Val MSE 9.2789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  93%|█████████▎| 93/100 [08:43<00:36,  5.17s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 092 | LR 0.000004 | Train MSE 0.2266 | Val MSE 0.1895 | Val MAE 1.4239 | Val MSE 9.2837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  94%|█████████▍| 94/100 [08:48<00:31,  5.19s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 093 | LR 0.000004 | Train MSE 0.2285 | Val MSE 0.1896 | Val MAE 1.4133 | Val MSE 9.2908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  95%|█████████▌| 95/100 [08:53<00:25,  5.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 094 | LR 0.000004 | Train MSE 0.2286 | Val MSE 0.1889 | Val MAE 1.4126 | Val MSE 9.2584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  96%|█████████▌| 96/100 [08:59<00:21,  5.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 095 | LR 0.000004 | Train MSE 0.2257 | Val MSE 0.1890 | Val MAE 1.4068 | Val MSE 9.2600\n",
            "Sample pred first 3 steps: [[0.00069465 0.00020624]\n",
            " [0.00137581 0.00053267]\n",
            " [0.00202738 0.00088248]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  97%|█████████▋| 97/100 [09:05<00:17,  5.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 096 | LR 0.000003 | Train MSE 0.2299 | Val MSE 0.1900 | Val MAE 1.4172 | Val MSE 9.3078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  98%|█████████▊| 98/100 [09:11<00:11,  5.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 097 | LR 0.000003 | Train MSE 0.2278 | Val MSE 0.1891 | Val MAE 1.4097 | Val MSE 9.2653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  99%|█████████▉| 99/100 [09:17<00:05,  5.83s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 098 | LR 0.000003 | Train MSE 0.2265 | Val MSE 0.1888 | Val MAE 1.4090 | Val MSE 9.2523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100/100 [09:23<00:00,  5.63s/epoch]\n",
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_49283/1114377084.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pt\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 099 | LR 0.000003 | Train MSE 0.2276 | Val MSE 0.1898 | Val MAE 1.4183 | Val MSE 9.3011\n",
            "Val MSE: 9.2364\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleLSTM(\n",
              "  (lstm): LSTM(6, 128, batch_first=True)\n",
              "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=120, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = SimpleLSTM(input_dim=6, hidden_dim=128)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        lr=0.0005,  # Lower learning rate\n",
        "        patience=20  # More patience\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_49283/1294397202.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model = torch.load(\"best_model.pt\")\n"
          ]
        }
      ],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model = torch.load(\"best_model.pt\")\n",
        "model = SimpleLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto2.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
