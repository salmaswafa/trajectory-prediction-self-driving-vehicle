{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model14.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('../cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('../cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+tklEQVR4nO3de1RU973//9cMlwERBhBkuF+SaDRekqhBvMRqG02Pscnp6cXmNJHvSW3TxObXhTnrVNu0xjaab5vm29auprfUNue0X/vtSW2TepJo7jHxHhPRqCQCAgIi10HuMPv3x4aREVCI4MyG52OtWTAzH4b37LV1Xnw+n/352AzDMAQAAGBRdn8XAAAAcCUIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNKC/V3A1eDxeFReXq7IyEjZbDZ/lwMAAAbBMAw1NjYqKSlJdvvA/S9jIsyUl5crNTXV32UAAICPobS0VCkpKQM+PybCTGRkpCTzYERFRfm5GgAAMBhut1upqanez/GBjIkw0zO0FBUVRZgBAMBiLjdFhAnAAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0sbERpPAqPXSt6WwaOnme6RIl7+rAQC/IMwAVtXWKO3/tdTVLk1ZQZgBMGYxzARY1UevmEEmNkuKn+zvagDAbwgzgFUVvGR+nfRpyWbzby0A4EeEGcCKPB7pw53m95Nv928tAOBnhBnAisoPS83VkiNKSsvxdzWA353fW6Hm96pkdBn+LgV+wARgwIp6emWyPiEFhfi1FMDfWj+qV/3fPpIkJU+Lk8Sw61hDzwxgRT1hZtIy/9YBBIAQ1ziFXR9r3gkiyIxF9MwAVtNcaw4zSdK1n/JvLUAACBofqrjcG/xdBvyInhnAaorekGRIE6eytgwAiDADWM+p18yvWZ/waxkAECgIM4DVFL1pfiXMAIAkwgxgLe5yqa5IstmltLn+rgYAAgJhBrCSorfMr64ZUpjTv7UAQIAgzABWUnbA/Jqa7d86ACCAEGYAK7F1/5PtbPVvHQAQQAgzgJXUnza/MsQEAF6EGcAqDv5OKnhRsgVJN/6rv6sBgIBBmAGs4MDT0j/yzO8Xr5cmXu/fegAggLCdARDIOlqkl9abvTKSNOcr0sK1/q0JAAIMYQYIVDWnpG13S+dOmPcXf0e69WHJxkZ6ANAbYQYIVBFxUnuTFDFR+uen2FQSAAZAmAECVZhTWvknKSrJDDYAgH4RZoBAljjD3xUAQMDjaiYAAGBphBkAgOW8UfqG/nzizzIMw9+lIAAwzAQAsJw1r66RJDV2NOor07/i52rgb/TMAAAs5Vj1Me/3cxPn+rESBArCDADAUv504k+SpBVZKzQtbpqfq0EgIMwAACyjw9OhV0pekSR9fvLn/VwNAgVhBgBgGacbTqupo0kRIRGaGT/T3+UgQDABGABgGZnOTD1/1/Oqaq6S3cbf4zARZgAAlhFkD1KGM0MZzgx/l4IAQqwFAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpi5QgcamtiCHgAAP2LRvCtwz5FC7apxS5IqPjFTNpvNzxUBADD20DNzBXqCzOddMX6uBACAsWvEw8yOHTuUnZ2t8PBwxcXF6bOf/azP8yUlJVqxYoUiIiIUFxenhx56SO3t7T5t8vPztWjRIoWHhys5OVkbN24MiKGdysU36pU5k/X4pBR6ZQAA8JMRHWZ69tlntXr1am3atElLliyRYRjKz8/3Pt/V1aXly5crPj5eu3fvVk1NjVatWiXDMLRlyxZJktvt1m233abFixfrwIEDKigoUG5uriIiIrR27dqRLH9Qbhgf7u8SAAAY02zGCHVxdHZ2KiMjQ48++qjuu+++ftu88MILuuOOO1RaWqqkpCRJ0rZt25Sbm6uqqipFRUXpqaee0rp163T27Fk5HA5J0uOPP64tW7aorKxsUD0ibrdbTqdTDQ0NioqKGr43CQAARsxgP79HbJjp3Xff1ZkzZ2S323XTTTcpMTFRn/70p3Xs2DFvmz179mjatGneICNJy5YtU1tbmw4dOuRts2jRIm+Q6WlTXl6u4uLifn93W1ub3G63zw0AAIxOIxZmCgsLJUkbNmzQd77zHf3jH/9QTEyMFi1apNraWklSZWWlEhISfH4uJiZGoaGhqqysHLBNz/2eNhfbvHmznE6n95aamjqs7w0AAASOIYeZDRs2yGazXfJ28OBBeTweSdK3v/1t/cu//ItmzZqlrVu3ymaz6S9/+Yv39fobJjIMw+fxi9v0jIwNNMS0bt06NTQ0eG+lpaVDfZsAAMAihjwBeM2aNVq5cuUl22RkZKixsVGSNHXqVO/jDodDWVlZKikpkSS5XC7t27fP52fr6urU0dHh7X1xuVx9emCqqqokqU+PTe/f03tYCgAAjF5DDjNxcXGKi4u7bLtZs2bJ4XDo5MmTWrBggSSpo6NDxcXFSk9PlyTl5OToscceU0VFhRITEyVJO3fulMPh0KxZs7xt1q9fr/b2doWGhnrbJCUlKSMjY6jlAwCAUWbE5sxERUXp/vvv1/e+9z3t3LlTJ0+e1Ne//nVJ0uc//3lJ0tKlSzV16lTdc889Onz4sF555RU9/PDDWr16tXfW8t133y2Hw6Hc3FwdPXpU27dv16ZNm5SXl8faLgAAYGTXmfnRj36k4OBg3XPPPWppaVF2drZeffVVxcSYK+YGBQVpx44deuCBBzR//nyFh4fr7rvv1hNPPOF9DafTqV27dunBBx/U7NmzFRMTo7y8POXl5Y1k6QAAwCJGbJ2ZQMI6MwAAWI/f15kBAAC4GggzAADA0ggzAADA0kZ0AjAAACOh+cg5BUWGymjvUtPBs7KHBSsoxqGQhAgFx4fL6PQoKDJU9ogQ2exc+TraEWYAAJbiae9S/d8+kqe5c1Dtg6IdCp8ep/HzkhQcEzbC1cEfGGYCAFiK0eFR+A1xsjmCJEmOLKciP5mmcTdNVLBrXJ/2XfVtOv/WGVVtOawud9vVLhdXAT0zAABLCYoIUcy/XKfof75WRqdH9tAgn+c7altU9fP3ZFzUc+Np7lTDztOK/dykq1kurgJ6ZgAAlmSz2/oEGUkKiQ1X0iNzNW5W3/37mg+eVdUv3lPHuearUSKuEnpmAACjjs1mU+znJylyUYraCusVmu5U7f89oc6qZrWXNKqrrk0h8X2HpGBNhBkAwKgVMnGcQiaaoSXh/7tJbR/Vy9PuUUhihJ8rw3AizAAAxgRbkF1hk2P9XQZGAHNmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmrOb0HmmDU3pqgXTsb5K73N8VARhFPjx4Vh/sLldXl8ffpQCDxqXZVvPX1ebXs/nSX1aZ37umS7dtlK5Z4r+6AFiep8ujN7cVqPV8h177rxPKfXy+IqId/i4LuCx6Zqzmxn81v4aOl1wzJJtdqsyXQlgACsCVMTzS9TmJ3vunj9WM7O8zDHW0tY7o78DYQM+M1SxeZ956NNVIH+6UUub4ryYAo0JQiF1zlmeooapZ46MdyroxfsR+l7v6nH7z4P+SJP3TNx7WlAWfGLHfhdGPMGN1EROkG7/k7yoQoOobDunQoS9Ikj655JSfq4EVhIYF65++PmPEf09waOiF70NCL9ESuDzCDDCK1dXt9XcJgA/D49FzT27WRwf2eB9LmjzFjxVhNCDMAKNYetpqBdnDFBTE7sAIDKfz3/MJMvagYHV1dvixIowGhBlgFLPbQ5WWdp+/ywC8MmberPlf+LI62lp17ZwcjZ8wQZGxcf4uCxZHmAEAqKGlQ1FhwbLZbCP+u+b+y8oR/x0YW7g0GwCgrz5zUNmbXtHbH1X7uxRgyOiZwYjq6vQoKJjMfLUYhiHP+fMKioz0dymwkNM1TdpXVCtJSnSG+bkaYOj4lMGIeu6n7+m5nx5WXWWTv0sZE05MmaqCObeo+te/8XcpsJC/v3dhW5TMOBbghPUQZjBiujo8Kv+wXqXH6xQcGuTvcsYU9/PP+bsEWMj1rkjNzYrVNz913VWZMwMMN4aZMGIMw9DNy9LU2e655P4up1valBIWqiD+E71ik/buUfOhQxq/hH26MHhLb3Bp6Q0uf5cBfGw2wzAMfxcx0txut5xOpxoaGhQVFeXvctBLh8fQ5N35au7eofdLibF6OMOl5DBWBAWAsW6wn98MM8GvSlrb1Ls/5v9W1Kpz9OdrAMAwYpgJfnXNuDCdXDBdx5tatL+hSWWt7UoPH3hIqodhdKmrq1lBQRGy2cjkADCWEWbgd8F2m6ZHjtP0yMEvuV9Xv1+HD39ZkjR92i80ceKykSoPABDg+JMWllRX+473+47Oev8VAgDwO3pmYEmZmQ8pKmqmWtsqlJT4BX+XAwDwI8IMLMluD1F8/Kf8XQYAIAAwzAQAACyNMAMACBhdbre/S4AFMcwEAAgInXV1+vDWRXJkZshx/RTF3f81ObKy/F0WLICeGQBAQGg5dEjq6FBbwYdyP/ecCv9pudoKC/1dFiyAMAMACAiRn/qUsv5nh/d+SFqaQjMz/VgRrIJhJgDAsCgvL9e2bdvU2dmpKVOmaMWKFUN+DUdWlqacOC5J8rS1sYs3BoWeGQABob653d8l4Ar95S9/kdvtVnNzsw4dOqTq6uorej274/JbmwASPTMAAsD5tk7N+sHLSosdp1syYjUnM1bZmbFKiQnnL3MLqa+v97l//PhxLVy40D/FYEwhzADwu+MVbnkMQ0XVTSqqbtKfD5ZKkhKdYbolM1ZzMsxwc+3E8YSbAHb//ffr6aefVnt7u4KCgjRx4kR/l4QxwmYYhuHvIkaa2+2W0+lUQ0ODoqKi/F0OgH40tHToYHGt9hfVan9xrfLLGtTp8f3vKTYiVHMyYnRL5gRlZ8ZqSmKUguyEm0DS1NSkxsZGJSQkEDxxxQb7+U2YARCQmts79V5JvfYVmQHncGmdWjs8Pm0iHcGa3RNusmI1PdmpkCCmAgKjBWGmF8IMYH3tnR7lnzHDzb7CWh06XafzbZ0+bcJDgjQrPUa3dM+5mZkarbCQID9VDOBKEWZ6IcwAo0+Xx9DxCrf2FtZ4h6bqmzt82oQG23VjarTmZsYqO2uCbk6LUXgo4SYgdLZLe34uvbJRmnCN9MU/ShOv93dVCDCEmV4IM8Do5/EY+ujcee0rrNHe7t6b6vNtPm2C7TbNSHF6h6Vmp8coMizETxWPcYYh/Z8bJPcZ8/5XXpVSZvm3JgQcwkwvhBlglGqpk9rOS9GpfZ4yuq+OMoelarSvqFYVDa0+bew26YYkp7K7e27mZMQoelzo1aoeB34rNVZKrunSNUskR6S/K0KAIcz0QpgBRqlDf5Cef0iKSpbS5kppOVL6fCn+esnuOxHYMAyV1bV4h6X2FdWqpLbZp43NJk1OiFR2Zqy39yZuPAu3jYRnC57V8drjSo9K15enfJkrn9AvwkwvhBlglHpts/TmjySjy/fx8FgpfZ55y1ggJUyT7H3nylQ0tGh/Ua32FtZqf1GNTp1r6tPmmvgIZWeZl4JnZ06Qyxk2Uu9mzDAMQwv/vFANbQ2SpNXTV+uhmx/yc1UIRISZXggzwCjW3iSVHZBK9kole6TS/VKHb4+LHE4pPccMNhkLJNeMfsPNucY2HSi+MCx1orKxT5v0CeO8weaWzFilxo4bqXc2arV0tuiJA0/oheIXNDlmsjYt2KTE8Yn+LgsBiDDTC2EGGEO6OqTy96TTb0vFu82Q035RKHFEXei1yVhoztnoJ9zUNbVrf/dCfvuKavRBuVsXreOn5Ojw7jk35tBUxoRxDJkAw4Qw0wthBhg+RkeHSv7tPnlaWhSalanYVasUfsMN/i5rYF2dUuURM9icfls6/Y7U5vZtE+aU0hdImbdKmQul+Cl95txIkrvVXKW4ZyG//lYpnhjpUHaW2Wszly0Y+mgvP6/zb51R8+EqOSbFKGJ2ghwZTgVFMfEafQVMmNmxY4c2btyoI0eOKCIiQrfeeqv++te/Xiign3/kTz31lO6//37v/fz8fK1Zs0b79+9XbGysvva1r+mRRx4Z9H8QhBlgeJ28eZY8zeZQzvjFi5X61C/8XNEQeLouhJuit8xwc3HPzbg4KWO+2WuTuUiKu86cHXyRprZOvVtSp32FZrh5r7Re7V2+qxRPiAg195bKitUtmbGa4oqSfYxuwdByvEY1/3lcF3dvjV+YrOjlWX6qCoFssJ/fI7rR5LPPPqvVq1dr06ZNWrJkiQzDUH5+fp92W7du1e233+6973Q6vd+73W7ddtttWrx4sQ4cOKCCggLl5uYqIiJCa9euHcnyAQwg6Ykn1PrBB6r70580cW2ev8sZGnuQlHSTeZv3DbPnpuJ9qegNqfgtc1iquVr64O/mTZLGu8whqcyFZu9NTKZksynCEayF18Vr4XXxkqTWji4dLqn3Dku9W1KnmqZ2vXisUi8eq5QkRYUFe8NNduYE3ZAUpeAxsgXD+T0VfYJMiGucHNdE+6cgjBoj1jPT2dmpjIwMPfroo7rvvvsGLsBm0/bt23XXXXf1+/xTTz2ldevW6ezZs3I4zEskH3/8cW3ZskVlZWWD6p2hZwYYGYZhjL4hlM526cwhM9gUvWlOKO7yXXxPztTuXpvucONM6fel2js9OlLWvQVDUa0OFdeqqd33yquI0CDdnB6jud1DUzNSnHIEj85Viut3FOr8W2d0dsoz6girVlbYtzTxzmx/l4UA5vdhpv379ys7O1u/+93v9LOf/UyVlZW68cYb9cQTT+iGXuPrNptNycnJam1tVWZmpu677z599atflb17vPree+9VQ0OD/v73v3t/5vDhw7r55ptVWFiozMzMPr+7ra1NbW0X/vNxu91KTU0lzAAYuo5W82qpnnBTdlDy+G6boJjM7mCzyAw5kQn9vlRnl0fHyt3enpv9RbVyt/ruL+UItuvmtBhvz81NaaNnfylPW6eqtx7TscwvyxPSLNfR+zT16/8h2zC8P8Mw9MOiSlW2d2jDNUlyhozowAOuEr8PMxUWFkqSNmzYoCeffFIZGRn68Y9/rEWLFqmgoECxsbGSpO9///v65Cc/qfDwcL3yyitau3atqqur9Z3vfEeSVFlZqYyMDJ/XTkhI8D7XX5jZvHmzHn300ZF6awDGkpCw7qCyUFq83rwUvHSfOd+m6A2p/LBUV2Te3n3G/Jm4yRd6bTIWSuPM/++Cg+yamRqtmanRWn1rljweQycqG73BZn9RrWqa2rWnsEZ7CmskfajQILtmpjqV3b2I36z0GI0LteYHtd0RrPjVMxT5x1nqCmlWcFu02sub5Ei/sj8y2zwefeVosXbVmBO7v5w4QbOc1jxG+HiG3DOzYcOGywaFnrkt//qv/6pf/epX+upXvyrJ7DFJSUnRD37wA33ta1/r92d//OMfa+PGjWpoMBdTWrp0qTIzM/WrX/3K2+bMmTNKSUnRnj17NHfu3D6vQc8MgKum1W1OIu7puanMl9T7v1Wb5Jpm9tpk3mpeEj7Asv2GYejUufPaW1jr3YahqrHv/lLTUy6EmzkZsRrvsMYHt+HxqKOkREExE1W/47SCY8MVtSz9iocqHz5Rqv+qqJEkzY8er2dvunY4ykUAGLGemTVr1mjlypWXbJORkaHGRvPqgKlTp3ofdzgcysrKUklJyYA/O3fuXLndbp09e1YJCQlyuVyqrKz0aVNVVSXpQg/NxRwOh3d+DQCMqLAoafLt5k2SmmvNS8CL3jR7b84dNwNOZb65S7QtSEq++cKcm9S5Uqi58J7NZtO1EyN17cRIfXluugzD0OmaZu0rqtG+7oBzpr5Fh0vqdbikXr9845TsNmlaslNzu1cpnpMZq6gA3DyzvaxMpz51m/f+tW+8rpAB/g8frNYuj5YcOKnCljY5Oxr11KyZWjKBP1jHoiGHmbi4OMXFxV223axZs+RwOHTy5EktWLBAktTR0aHi4mKlp6cP+HOHDx9WWFiYoqOjJUk5OTlav3692tvbFRpqrkOwc+dOJSUl9Rl+AgC/GxcrTVlh3iSp8Wx3r80bZripKzLn4JQdkHY/KdlDpJTZZrjJWCCl3iKFhEsyw01GXIQy4iL0xTlpkqTS2mZvr83eohqV1rboSFmDjpQ16NdvFvbZPPOWjFg5x/k/3HTV1vrcbz127IrDzLbKWhW2tOkrZf+tH5zaIn04RXpgT7+X0WN0G9F1Zr75zW/qv//7v/W73/1O6enp+tGPfqTnn39eJ06cUExMjJ5//nlVVlYqJydH4eHheu2117R27Vrl5ubqpz/9qSSpoaFBkydP1pIlS7R+/Xp9+OGHys3N1Xe/+91BX5rN1UwAAkZ9Sfd8mzfNkOM+4/t8UKiUPLt7deL5Usot3p6b/pTXt3h7bvYW1qi4pu/mmVNcUd4JxdmZsYqJ8M8Cda0nC1Tz9G/VfqpQGX/eJlvwlQ2PVbS166Z3PtC3in6jb5b8lwx7iGzfrR6mahEI/H41k2T2xKxbt07/+Z//qZaWFmVnZ+snP/mJ92qmF198UevWrdNHH30kj8ejrKwsfeUrX9GDDz6o4F4neX5+vh588EHt379fMTExuv/++/Xd736XRfMAWJthSLWF5gJ+xW+ZXxsrfNvYQ8xhqfR55irFadkDzrmRpLPuVu0trNHeQjPgFFb33TzzelfkhZ6bTGvvDF7W2q5/27tfP2h4SbcseVCKdPm7JAyjgAgzgYIwAwyvgrONau/0aFqy8/KNMXg+4aZ7+4WLe25sQVLiDCl9vtl7k5YjhUcP+JJV7lbtKzJ7bfYV1eqjqvN92lw3cbx3b6m5mbGaGGWNncFP1p5UQV2BVlyzwt+lYIQQZnohzADD482Cc7r3d/slSQuvi9N/3seCZyPKMKS64u5NM982v9afvqhR99VS6Qu6e2/mSREDz2usPt/Wvf3CwDuDZ8ZFeDfPzM6coKTo8OF9X8OguqVai//fYknSt7O/rZXXX/rCFFgTYaYXwgwwPP75F2/rcEm9JOnT01za8qWbxsxS/AGjoexCsDn9tlTzUd82cZO7g818KT1nwBWKJam2qd27iN++wlodr3Tr4k+F1Nhw73yb7MwJSo0N9/vKz4ZhaMYzM7z3j9x7xO81YfgRZnohzADDo62zS5/9xTv66cqbdO3E8f4uB5LUWHlhN/Dit81LwS8WnSalzTODTfp8acK1A17x09DcoQPFtdpfbF4xdbTcra6L9lNKdIbplu5gc0tmrK6Jj/BLkKhuqVbui7n62ZKfKcvJRpWjEWGmF8IMgDGjudYMNiV7zHk3lUckw3cnb0XES2lzzYCTNldyzZCC+r+y6Hxbpw4Wm2vc7C+q1ful9eq8KNzEjXcoO9PcFTw7K1aTJkaO2Z3BMbwIM70QZgCMWW2N5maZJXvMkFN2sO/GmaHjpZQ55tBU2lzz0vABLgdvae/SuyV13rVuDpfWq73TNyzFjAvRnAwz3MzNmqApiVEKItzgYyDM9EKYAYBunW3mflI9vTcl+6S2Bt829hAp6cbu3psc89a9v9TFWju69H5pvQ50994cLK5TS4fvzuCRYcGakxHr7b2ZluxUCHOtMAiEmV4IMwAwAI9HqvrgQs9NyV6psbxvO++k4u7bAJOKO7o8yj/T4L1i6mBxnRrbfHcGHxcapFnpMZrbvc7NjBSnHMGjY2dwDC/CTC+EGQAYJMMwL/8u2Xsh3FSf7NsuOq37aqnuq6Zis/qdVNzlMfRBudu8Wqp73k1DS4dPm7AQu25KjfFeCn5TWrTCQgg3IMz4IMwAwBVoqukektpjXjlVcUQyfIeSFJnYvZDffHOfqQGumPJ4DJ0826h9hRfCTU1Tu0+b0GC7bkyN1txMcyG/WekxCg8l3IxFhJleCDMAMIx6JhWffscMN2UHJY9vb4vGJ/Ra62a+FH+9ZO87T8YwDJ06d157u3cF31dYo6pG3wnKIUE2TU92Krt7Z/DZGbEa77iyfZ1gDYSZXggzADCCOlrMXcCL3zYvBy870PeKqXETzInEGd0rFSdMk+x9e1sMw1BxTXP33lJm701FQ6tPmyC7TdOSonzCjTPc/zuDY/gRZnohzADAVdTRKp051L0Nw26zF6ezxbdNmLNXuJk/4Fo3hmGotLZFe7tXKN5fXKPSWt/XstmkqYlR3kX8/LkzOIYXYaYXwgwA+FFne/fl4N1bMJTsldov2vAyNNK8FDxjvrnPVNKNUlD/vS1n6lvMvaW6h6aK+tkZfHJCpHdC8S2ZsYqPtO7O4GMZYaYXwgwABJCuTqny/e4tGHZLp/f0XesmJEJKveVCuEm+WQruP5BUuVu1t3u+zUA7g18TH+EdlpqbNUEJFtkZfKwjzPRCmAGAAObpks4e7RVu3pFaan3bBIeZqxT3zLlJmSOF9L+bd/X5Nu3vvlJqb2FNvzuDZ0wY591fau41E5QcgDuDgzDjgzADABbi8UjnTlyYc3P6banpnG+boFBz24WM+WbASbllwC0Y6pt7dgY3dwf/oNyti7aXUkrMhZ3B52YFxs7gIMz4IMwAgIUZhlT9oXR6txluit+Wzlf6trGHmENRPROKU7MlR/87u7tbO8zNMwtrtbeoVkfPNFxyZ/DsrFhlxflnZ/CxjjDTC2EGAEYRw5BqC7uDTXfPjfuMbxt7sJR4ozkklbHAnFwc5uz35c63derQ6TrvnJsjZfXq6PL9aIyPdJgbZ2bGKjtrgq6bOJ5wcxUQZnohzADAKGYYUl3RhTk3xW9LDSW+bWx2yTX9whYMaTlSRFy/L+fdGbywRnuLavVePzuDx0aEak5GjLfnZoorSnZ2Bh92hJleCDMAMMbUl5ih5nT3hOLawr5t4iZ3Xy3VHXCikvp9qdaOLr1XWt8976ZGh07XqbXDN9xEhQXrlu5dwbMzJ+iGpCgFszP4FSPM9EKYAYAxzl0hlbzTHXDekc4d79smJkNK67Uz+ACbZ7Z3epR/pl57C80rpg4W16qp3XevqojQIM3KMBfwy86M1XR2Bv9YCDO9EGYAAD56Ns883R1uKo9Ihm9vi8YnmMNRPeFm4tR+t2Do7PLoWPfO4D2XhLtbO33a9OwMfktmrLKzYnVTKptnDgZhphfCDADgklrd3Ztnvm2GnDOHpC7f3bzlcJoTidNzzB6cpJuk4L7bJng8hk5UNmqfdwuGWtVevDN4kF0HH/mUosLYU+pSCDO9EGYAAEPS0SKdedfstSl5xww6F2/BEBxmrnWTPs8MOCm39Hs5uGEY+qjqvPZ199rsK6pRZFiIXs5bdJXejHURZnohzAAArkhXp3Q239x6oeQdM+Q01/i2sQWZe0qlzzMnFafNlcJj+ryUYRhqaOlQ9Dg2w7wcwkwvhBkACGxGh0fN75/TieYCGZPCNSthVmCv4+JdyK97WOr0O1JD6UWNbFLCtF5XTM2XIib4pVyrIsz0QpgBgMDmLjwn969PqNXWrs9NzlOXzaP8Vfn+Lmto6kvMnpue3cFrPurbZuLUC6sUZywYcK0bmAb7+R18FWsCAKBfDlekTjlKddpRoS55Lv8DgSg6zbzN/KJ5v/Fs9xYM3eHm3Amp6gPztv/XZpv4KVLmwu6As4Cem4+JnhkAgN8ZhqH9lfsVbA9WkC1I18der7DgsMv+3Hsvlyh5Uozi0yKvQpVXqKm6e/PMt6Xit8xQc7GJN3SHm4Xm8FQ/c27GEoaZeiHMAMDoc/TNM3rjTye992d+KlULPnedHysaoqaaC5tnFr3Vz0J+NilxhhlsMm8117wJG1ufYQwzAQBGtfBI3zVazte2+amSjyligjT1TvMmSefPmT02xW+Z4abmQ6niffO25+cXrpbK6O65SZs74M7gV9Pv1z6gmrISLb3/IU1fvNQvNdAzAwCwtPN1raotb1JoeLBcWf3vjG1J7orujTPfNMNNXZHv8/ZgKelmc75N5kIpda4UOu6ql/njL94hSZq+ZKmWfu2hYX1thpl6IcwAACyvocwMNT09NxfvDG4PkVJmm+EmY4GUmi2FhI94WR/uf0cFe9/W0vsfUkioY1hfmzDTC2EGADDq1J3uHpbqnnPjLvN9PihUSpnTPedmofl98PCGjZFGmOmFMAMAGNUMwxyGKnrLvGKq6C2psdy3TXCYGWgybzV7bpJn97u3VCAhzPRCmAEAjCmGIdUWSkVvXhiWaqrybRMcLqVlX5hQnHyzFBRYG18SZnohzAAAroby+haNCw0KvH2XDEOqLrgQbIp3S83Vvm1CIswrpDIWmL03iTdKQf696Jkw0wthBgAw0o6eadAdW3ZLkl785kJd7wrgzxvDkKqOX7haqvhtqaXWt01opLlpZs8ifq7pkj3oqpbJOjMAAFxFX/zVHu/3kWGBNVzTh80mJUw1b9lflTwec0Xinp6b029LrfXShy+ZN0kKizZ7be78ecCtTEyYAQBgGPy/+3P0o5dOavn0RCVHj/wl0cPKbpdc08zb3K9Lni6pMr9XuHnHDDen35EcgbeWD8NMAADg0ro6pYr3JHe5NPUzV+3XMswEAACGR1CwuSBfgLL7uwAAAEajzs5Of5cwZtAzAwDAMHvmmWdUWFgoSbr//vvlcrn8XNHoRs8MAADDrCfISFJRUdElWmI4EGYAABhmn/jEJzRu3Di5XC5lZ2f7u5xRj6uZAABAQBrs5zc9MwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNJGLMy8/vrrstls/d4OHDjgbVdSUqIVK1YoIiJCcXFxeuihh9Te3u7zWvn5+Vq0aJHCw8OVnJysjRs3agwsXAwAAAZhxHbNnjdvnioqKnwee+SRR/Tyyy9r9uzZkqSuri4tX75c8fHx2r17t2pqarRq1SoZhqEtW7ZIMpcyvu2227R48WIdOHBABQUFys3NVUREhNauXTtS5QMAAIsYsTATGhrqs+V5R0eHnnvuOa1Zs0Y2m02StHPnTn3wwQcqLS1VUlKSJOnHP/6xcnNz9dhjjykqKkp//OMf1draqt///vdyOByaNm2aCgoK9OSTTyovL8/7WgAAYGy6anNmnnvuOVVXVys3N9f72J49ezRt2jRvkJGkZcuWqa2tTYcOHfK2WbRokRwOh0+b8vJyFRcX9/u72tra5Ha7fW4AAGB0umph5umnn9ayZcuUmprqfayyslIJCQk+7WJiYhQaGqrKysoB2/Tc72lzsc2bN8vpdHpvvX8nAAAYXYYcZjZs2DDgxN6e28GDB31+pqysTC+99JLuu+++Pq/X3zCRYRg+j1/cpmfy70BDTOvWrVNDQ4P3VlpaOtS3CQAALGLIc2bWrFmjlStXXrJNRkaGz/2tW7dqwoQJ+sxnPuPzuMvl0r59+3weq6urU0dHh7f3xeVy9emBqaqqkqQ+PTY9HA6Hz7AUAAAYvYYcZuLi4hQXFzfo9oZhaOvWrbr33nsVEhLi81xOTo4ee+wxVVRUKDExUZI5KdjhcGjWrFneNuvXr1d7e7tCQ0O9bZKSkvqEJgAAMPaM+JyZV199VUVFRf0OMS1dulRTp07VPffco8OHD+uVV17Rww8/rNWrVysqKkqSdPfdd8vhcCg3N1dHjx7V9u3btWnTJq5kAgAAkq5CmHn66ac1b948TZkypc9zQUFB2rFjh8LCwjR//nx94Qtf0F133aUnnnjC28bpdGrXrl0qKyvT7Nmz9cADDygvL095eXkjXToAALAAmzEGltJ1u91yOp1qaGjw9vgAAIDANtjPb/ZmAgAAlkaYAQAAlkaYAQAAlkaYAQAAlkaYAQAAlkaYAQAAlkaYAYArVFt+Rif3vKXW8+f9XQowJg15OwMAgK/X/vBrFb93SMnXT9XKR3/o73KAMYeeGQC4QnGp6QoOdShj5ix/lwKMSawADADDxPB4ZLPzNyIwXFgBGACuMoIM4B/8ywMAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAPzt0ulYrf71HtU3t/i4FsKRgfxcAAGNZZ5dHX/r1PrV3eVTb1K7YiFB/lwRYDj0zAOBHwUF2PbxskiQpbjxBBvg4bIZhGP4uYqS53W45nU41NDQoKirK3+UAAIBBGOznNz0zAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzuCINDe+qvb3a32UAAMYwwgw+tq6uNuUf/Ybe2bNY9Q2H/F0OAGCMGrEw8/rrr8tms/V7O3DggLddf8//8pe/9Hmt/Px8LVq0SOHh4UpOTtbGjRs1Btb6C3hnzz6ntrZKBQdHKXL8NH+XAwAYo0Zsb6Z58+apoqLC57FHHnlEL7/8smbPnu3z+NatW3X77bd77zudTu/3brdbt912mxYvXqwDBw6ooKBAubm5ioiI0Nq1a0eqfAzC8RPfUkdHqCbETlVQkMPf5QAAxqgRCzOhoaFyuVze+x0dHXruuee0Zs0a2Ww2n7bR0dE+bXv74x//qNbWVv3+97+Xw+HQtGnTVFBQoCeffFJ5eXl9XgtXR2dnoyTp8LvLZbc7lZh4VgkJCX6uKjB1dnbKMAyFhIT4uxQAGJWu2pyZ5557TtXV1crNze3z3Jo1axQXF6c5c+bol7/8pTwej/e5PXv2aNGiRXI4Lvzlv2zZMpWXl6u4uLjf39XW1ia32+1zw/CqrX1HHR0OtbWNV0tLl09v2lj24rkGfebdD/XYqXK9XutWc5dH+/fv12OPPaZHH31UdXV1/i4RAEadqxZmnn76aS1btkypqak+j3//+9/XX/7yF7388stauXKl1q5dq02bNnmfr6ys7PMXf8/9ysrKfn/X5s2b5XQ6vbeLfyeu3LlzB1V4apYkKTY2VmFhYX6uKDC8Xd+o/Q1N2lJSpZXvF2rym+/r30trZUgyDEOvvfaav0sEgFFnyGFmw4YNA07s7bkdPHjQ52fKysr00ksv6b777uvzet/5zneUk5OjG2+8UWvXrtXGjRv1ox/9yKfNxUNJPZN/BxpiWrdunRoaGry30tLSob5NXMbZsw2qqrpGknTjjTf6t5gAsjolXv/n+lR90RWrZEeIOmRTlz1INkkxMTFavny5v0sEgFFnyHNm1qxZo5UrV16yTUZGhs/9rVu3asKECfrMZz5z2defO3eu3G63zp4152C4XK4+PTBVVVWSNOAcDYfD4TMsheG3ZMkP1dm5Q0lJyZo6dYa/ywkYaeEOpYU79KXECTIMQ0fq3Gpsmqj5n7t90PO7PB5DH+6v1Lmy85p7Z5aCQ4JGuGoAsLYhh5m4uDjFxcUNur1hGNq6davuvffeQU2APHz4sMLCwhQdHS1JysnJ0fr169Xe3q7Q0FBJ0s6dO5WUlNQnNOHqWrqUXoZLsdlsmhnrlGKHNp+o8PA5vfz745KkylMN+tx/zL7MTwDA2Dbic2ZeffVVFRUV9TvE9Pzzz+s3v/mNjh49qlOnTum3v/2tvv3tb+urX/2qt2fl7rvvlsPhUG5uro4ePart27dr06ZNXMmEUSs49MI/S3d1ix8rAQBrGLFLs3s8/fTTmjdvnqZMmdLnuZCQEP3iF79QXl6ePB6PsrKytHHjRj344IPeNk6nU7t27dKDDz6o2bNnKyYmRnl5ecrLyxvp0gG/aGvu9H5/2/+6wY+VAIA12IwxsJSu2+2W0+lUQ0ODoqKi/F0OcFmGYdDzCGDMG+znN3szAQGIIAMAg0eYAQAAlkaYAQAAlkaYATAqeTyjfjoggG4jfjUTAPjDn3+wX54uQxOSIxSfFqmJaVGamBklRzj/7QGjDf+qAYw6XR0e1VU2y/AYqj/brFPvnjOfsEmxiRFKvDZaidc4lXRdtCJj2VcMsDouzQYw6hiGoWZ3u2rPNOlcWaPOlTSqqtgtd3Vrn7ZRcWFKmhSj5EnRSpkco/ExhBsgUAz285swA2DMaHa3q/JUg8pP1aviw3qdKz0v46K5NbFJEcqYPkFZN03UxPRILpMH/Igw0wthBkB/2ls7VXmqQWcK6lR2sl7nTrvV+3/EyNgwZUyfoPQZcUq6LlohoWz6CVxNhJleCDMABqO1qUMlH9So6P1qFefXqLOty/ucPcimhMwoJXcPSbmynAom3AAjijDTC2EGwFB1tHep7ESdivOrVXK0Rufr2nyeDwq2y3WNU6lTYpRyfazi0yJltzMkBQwnwkwvhBkAV8IwDLmrW3TmZL3OFNTpzMk6NTW0+7RxjAtWyvUxSp0Sq6kLkphrAwyDwX5+c2k2gFHP8Hi07Xv/ocTrJunaOTlKmjRF9qDBDxHZbDY548fJGT9OUxckyTDMS75Lj9ep7EStzhTUq625U6fePaeGcy26YWHyCL4bABcjzAAY9coLTqi84LjKC47r0I6/KzR8nFJvmK7UqTOUPHmK4jMyFRQcMujXs9lsinFFKMYVoRmLU+Tp8qjqdKNKj9cqPDJ0BN8JgP4wzARg1Ovs6FDxe4dUsHe3it47pNbzjT7PBwUHKzYlTbFJKUqaNEU3f3qFnyoF0BvDTADQLTgkRNfOmatr58yVx9OlqsJTKjl2RGdOHFP5yeNqbTqvc8WFOldcqLryM4QZwGIIMwDGFLs9SK5rJ8l17STpzs/JMAw1VJ1Vdelp1ZSeVtj4yEv+fHNDvTxdXRofO+EqVQzgcggzAMY0m82m6ASXohNcunZ29mXb57+6U7u3PaOYpBRlzLhJ6TNuUuoN0xUaFn4VqgXQH8IMAAxBY021ZLOprrxMdeVlOvzi87IHBSvxuslKmzZTadNnKvHaSUOaUAzgyjABGACGqPX8eZUeO6LiI+/q9JHDaqg66/N8sMOh5MlTlTp1ulJvmK6ErOsUFMzfjsBQsWheL4QZACOpvrJCp/PfU8nR91V67IhaGt0+z4c4wpQ0eYpSrr9BKVOmyXXdZAWH0HMDXA5hphfCDICrxfB4VFNWopJj+Sr7IF+lH+T3uRQ8ONTRK9zcoNQbZvipWiCwEWZ6IcwA8BfD41F1WYnKPshX2YkPVPZBvpob6r3Px2dk6d7//TP/FQgEMNaZAYAAYLPbFZ+Wofi0DN10+woZhqGashKVfpCvMyc+0ITkVH+XCFgePTMAACAgDfbz234VawIAABh2hBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBpIxpmCgoKdOeddyouLk5RUVGaP3++XnvtNZ82JSUlWrFihSIiIhQXF6eHHnpI7e3tPm3y8/O1aNEihYeHKzk5WRs3bpRhGCNZOgAAsIjgkXzx5cuXa9KkSXr11VcVHh6un/zkJ7rjjjt06tQpuVwudXV1afny5YqPj9fu3btVU1OjVatWyTAMbdmyRZLkdrt12223afHixTpw4IAKCgqUm5uriIgIrV27diTLBwAAFmAzRqiLo7q6WvHx8XrzzTe1cOFCSVJjY6OioqL08ssv65Of/KReeOEF3XHHHSotLVVSUpIkadu2bcrNzVVVVZWioqL01FNPad26dTp79qwcDock6fHHH9eWLVtUVlYmm8122VrcbrecTqcaGhoUFRU1Em8XAAAMs8F+fo/YMNOECRM0ZcoUPfPMM2pqalJnZ6d+9atfKSEhQbNmzZIk7dmzR9OmTfMGGUlatmyZ2tradOjQIW+bRYsWeYNMT5vy8nIVFxePVPkAAMAiRmyYyWazadeuXbrzzjsVGRkpu92uhIQEvfjii4qOjpYkVVZWKiEhwefnYmJiFBoaqsrKSm+bjIwMnzY9P1NZWanMzMw+v7utrU1tbW3e+263exjfGQAACCRD7pnZsGGDbDbbJW8HDx6UYRh64IEHNHHiRL311lvav3+/7rzzTt1xxx2qqKjwvl5/w0SGYfg8fnGbnpGxgYaYNm/eLKfT6b2lpqYO9W0CAACLGHLPzJo1a7Ry5cpLtsnIyNCrr76qf/zjH6qrq/OOc/3iF7/Qrl279Ic//EHf+ta35HK5tG/fPp+fraurU0dHh7f3xeVyeXtpelRVVUlSn16dHuvWrVNeXp73vtvtJtAAADBKDTnMxMXFKS4u7rLtmpubJUl2u2/nj91ul8fjkSTl5OToscceU0VFhRITEyVJO3fulMPh8M6rycnJ0fr169Xe3q7Q0FBvm6SkpD7DTz0cDofPHBsAADB6jdgE4JycHMXExGjVqlV6//33VVBQoH//939XUVGRli9fLklaunSppk6dqnvuuUeHDx/WK6+8oocfflirV6/29ubcfffdcjgcys3N1dGjR7V9+3Zt2rRJeXl5g7qSCQAAjG4jFmbi4uL04osv6vz581qyZIlmz56t3bt36+9//7tmzpwpSQoKCtKOHTsUFham+fPn6wtf+ILuuusuPfHEE97XcTqd2rVrl8rKyjR79mw98MADysvL8xlGAgAAY9eIrTMTSFhnBgAA6/H7OjMAAABXA2EGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYWrC/CwAwetS01OjF4hdV21qrhckLdePEG/1dEoAxgDADYNh8e/e39Xb525KkPxz7g/7xz/+QK8Ll56oAjHYMMwEYNjdNvMn7fVtXm5o7m/1YDYCxgp4ZAMPmazO/pk+lf0r7KvapoK5A6ZHp/i4JwBhAmAEwrK6JvkbXRF/j7zIAjCEMMwEAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsbE7tmG4YhSXK73X6uBAAADFbP53bP5/hAxkSYaWxslCSlpqb6uRIAADBUjY2NcjqdAz5vMy4Xd0YBj8ej8vJyRUZGymazfezXcbvdSk1NVWlpqaKiooaxwrGJ4zn8OKbDi+M5/Dimw2u0H0/DMNTY2KikpCTZ7QPPjBkTPTN2u10pKSnD9npRUVGj8qTxF47n8OOYDi+O5/DjmA6v0Xw8L9Uj04MJwAAAwNIIMwAAwNIIM0PgcDj0ve99Tw6Hw9+ljAocz+HHMR1eHM/hxzEdXhxP05iYAAwAAEYvemYAAIClEWYAAIClEWYAAIClEWYAAICljfkw8+abb2rFihVKSkqSzWbT3/72N5/nDcPQhg0blJSUpPDwcH3iE5/QsWPHfNq0tbXpG9/4huLi4hQREaHPfOYzKisru4rvIrBc7pjm5ubKZrP53ObOnevThmNq2rx5s+bMmaPIyEhNnDhRd911l06ePOnThnN0aAZzTDlHB++pp57SjBkzvIu25eTk6IUXXvA+z/k5dJc7ppyffY35MNPU1KSZM2fq5z//eb/P//CHP9STTz6pn//85zpw4IBcLpduu+02735PkvTNb35T27dv17Zt27R7926dP39ed9xxh7q6uq7W2wgolzumknT77beroqLCe/uf//kfn+c5pqY33nhDDz74oPbu3atdu3aps7NTS5cuVVNTk7cN5+jQDOaYSpyjg5WSkqLHH39cBw8e1MGDB7VkyRLdeeed3sDC+Tl0lzumEudnHwa8JBnbt2/33vd4PIbL5TIef/xx72Otra2G0+k0fvnLXxqGYRj19fVGSEiIsW3bNm+bM2fOGHa73XjxxRevWu2B6uJjahiGsWrVKuPOO+8c8Gc4pgOrqqoyJBlvvPGGYRico8Ph4mNqGJyjVyomJsb47W9/y/k5jHqOqWFwfvZnzPfMXEpRUZEqKyu1dOlS72MOh0OLFi3SO++8I0k6dOiQOjo6fNokJSVp2rRp3jbo6/XXX9fEiRM1adIkrV69WlVVVd7nOKYDa2hokCTFxsZK4hwdDhcf0x6co0PX1dWlbdu2qampSTk5OZyfw+DiY9qD89PXmNho8uOqrKyUJCUkJPg8npCQoNOnT3vbhIaGKiYmpk+bnp+Hr09/+tP6/Oc/r/T0dBUVFemRRx7RkiVLdOjQITkcDo7pAAzDUF5enhYsWKBp06ZJ4hy9Uv0dU4lzdKjy8/OVk5Oj1tZWjR8/Xtu3b9fUqVO9H5ycn0M30DGVOD/7Q5gZBJvN5nPfMIw+j11sMG3Gqi9+8Yve76dNm6bZs2crPT1dO3bs0Gc/+9kBf26sH9M1a9boyJEj2r17d5/nOEc/noGOKefo0EyePFnvvfee6uvr9eyzz2rVqlV64403vM9zfg7dQMd06tSpnJ/9YJjpElwulyT1SbJVVVXevzRcLpfa29tVV1c3YBtcWmJiotLT0/Xhhx9K4pj25xvf+Iaee+45vfbaa0pJSfE+zjn68Q10TPvDOXppoaGhuvbaazV79mxt3rxZM2fO1E9/+lPOzysw0DHtD+cnYeaSMjMz5XK5tGvXLu9j7e3teuONNzRv3jxJ0qxZsxQSEuLTpqKiQkePHvW2waXV1NSotLRUiYmJkjimvRmGoTVr1uivf/2rXn31VWVmZvo8zzk6dJc7pv3hHB0awzDU1tbG+TmMeo5pfzg/xdVMjY2NxuHDh43Dhw8bkownn3zSOHz4sHH69GnDMAzj8ccfN5xOp/HXv/7VyM/PN770pS8ZiYmJhtvt9r7G/fffb6SkpBgvv/yy8e677xpLliwxZs6caXR2dvrrbfnVpY5pY2OjsXbtWuOdd94xioqKjNdee83IyckxkpOTOab9+PrXv244nU7j9ddfNyoqKry35uZmbxvO0aG53DHlHB2adevWGW+++aZRVFRkHDlyxFi/fr1ht9uNnTt3GobB+flxXOqYcn72b8yHmddee82Q1Oe2atUqwzDMS1+/973vGS6Xy3A4HMatt95q5Ofn+7xGS0uLsWbNGiM2NtYIDw837rjjDqOkpMQP7yYwXOqYNjc3G0uXLjXi4+ONkJAQIy0tzVi1alWf48UxNfV3HCUZW7du9bbhHB2ayx1TztGh+bd/+zcjPT3dCA0NNeLj441PfvKT3iBjGJyfH8eljinnZ/9shmEYV68fCAAAYHgxZwYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFja/w83DODAABPBugAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0), # (1,2)\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32), # scalar e.g. 7.0\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoRegressiveLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=2, num_layers=1, future_steps=60):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.future_steps = future_steps\n",
        "\n",
        "        # Encoder: takes in past trajectory\n",
        "        self.encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Decoder: predicts future positions one step at a time\n",
        "        self.decoder = nn.LSTM(input_size=2, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data, forcing_ratio = 0.5):\n",
        "    # def forward(self, data):\n",
        "        x = data.x[..., :5]  # Use position + velocity\n",
        "        x = x.reshape(-1, 50, 50, 5)[:, 0, :, :]  # (batch, 50, 5), ego only\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        if self.training:\n",
        "            future = data.y.view(batch_size, 60, 2) # (batch, 60, 2)\n",
        "\n",
        "        device = x.device\n",
        "\n",
        "        # Encode past\n",
        "        _, (hidden, cell) = self.encoder(x)\n",
        "\n",
        "        # Initialize decoder input with last observed position\n",
        "        decoder_input = x[:, -1, :2].unsqueeze(1)  # (batch, 1, 2)\n",
        "        \n",
        "        # print(\"decoder_input.shape - initial\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(self.future_steps):\n",
        "            output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
        "            pred = self.out(output)  # (batch, 1, 2)\n",
        "            outputs.append(pred)\n",
        "\n",
        "            # TODO: remove forcing ratio?\n",
        "            if self.training and random.random() < forcing_ratio:\n",
        "            # if self.training:\n",
        "                decoder_input = future[:, t].unsqueeze(1)  # ground truth\n",
        "                # print(\"decoder_input.shape - teacher forcing\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "            else:\n",
        "                decoder_input = pred.detach()  # predicted output as next input\n",
        "                # print(\"decoder_input.shape - autoreg\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)  # (batch, 60, 2)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Example of basic model with simple attention mechanism\n",
        "# class SimpleLSTMWithAttn(nn.Module):\n",
        "#     def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2):\n",
        "#         super(SimpleLSTMWithAttn, self).__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "#         # Simple attention mechanism\n",
        "#         self.attention = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "#         # Add multi-layer prediction head for better results\n",
        "#         self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "#         # Initialize weights properly\n",
        "#         for name, param in self.named_parameters():\n",
        "#             if 'weight' in name:\n",
        "#                 nn.init.xavier_normal_(param)\n",
        "#             elif 'bias' in name:\n",
        "#                 nn.init.constant_(param, 0.0)\n",
        "        \n",
        "#     def forward(self, data):\n",
        "#         x = data.x[..., :5]\n",
        "#         x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "#         x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "#         # Process through LSTM\n",
        "#         lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_dim)\n",
        "        \n",
        "#         # Apply attention mechanism\n",
        "#         attention_weights = torch.softmax(self.attention(lstm_out), dim=1)  # (batch_size, seq_len, 1)\n",
        "#         attended_features = torch.sum(lstm_out * attention_weights, dim=1)  # (batch_size, hidden_dim)\n",
        "        \n",
        "#         # Process through prediction head\n",
        "#         features = self.relu(self.fc1(attended_features))\n",
        "#         features = self.dropout(features)\n",
        "#         out = self.fc2(features)\n",
        "        \n",
        "#         # Reshape to (batch_size, 60, 2)\n",
        "#         return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        forcing_ratio = max(0.0, 1.0 - epoch / 50)\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch, forcing_ratio=forcing_ratio)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                # batch.scale turns scale from 7.0 or (1,) shape i.e. scalar to (B,) shape\n",
        "                # batch.origin turns origin from (1,2) shape to (B,2)\n",
        "                \n",
        "                # then .view(-1, 1, 1) turns scale from (B,) to (B, 1, 1)\n",
        "                # then .unsqueeze(1) turns origin from (B, 2) to (B, 1, 2)\n",
        "                # because pred and y have shapes (B, 60, 2) so these transformations make them compatible for the calculation\n",
        "                \n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = AutoRegressiveLSTM(input_dim=5, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr = 0.007 => 8.946\n",
        "        lr=0.007,  # Lower learning rate\n",
        "        patience=20,  # More patience\n",
        "        epochs=100\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_73396/2425023728.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_73396/2425023728.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future - origin\n",
            "Epoch:   1%|          | 1/100 [00:19<32:20, 19.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.006650 | Train MSE 0.6946 | Val MSE 7.6300 | Val MAE 13.3659 | Val MSE 373.8692\n",
            "Sample pred first 3 steps: [[-0.04502406 -0.01359732]\n",
            " [-0.05280701 -0.01703607]\n",
            " [-0.07282741 -0.0424345 ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: inf -> 7.629984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 2/100 [00:39<31:58, 19.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.006317 | Train MSE 0.0028 | Val MSE 5.9698 | Val MAE 10.1509 | Val MSE 292.5221\n",
            "Validation improved: 7.629984 -> 5.969840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 3/100 [00:58<31:38, 19.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.006002 | Train MSE 0.0007 | Val MSE 6.2347 | Val MAE 11.1051 | Val MSE 305.4987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 4/100 [01:18<31:18, 19.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.005702 | Train MSE 0.0035 | Val MSE 11.4727 | Val MAE 15.0821 | Val MSE 562.1640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [01:37<30:54, 19.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.005416 | Train MSE 0.0005 | Val MSE 1.8349 | Val MAE 5.8826 | Val MSE 89.9098\n",
            "Validation improved: 5.969840 -> 1.834895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|▌         | 6/100 [01:57<30:37, 19.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.005146 | Train MSE 0.0002 | Val MSE 23.5929 | Val MAE 20.0733 | Val MSE 1156.0527\n",
            "Sample pred first 3 steps: [[-0.00891543  0.01307477]\n",
            " [-0.00369835  0.00968042]\n",
            " [-0.00426701 -0.00613374]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 7/100 [02:16<30:21, 19.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.004888 | Train MSE 0.0025 | Val MSE 3.0984 | Val MAE 7.0086 | Val MSE 151.8196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 8/100 [02:36<30:06, 19.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.004644 | Train MSE 0.0023 | Val MSE 16.9046 | Val MAE 20.0595 | Val MSE 828.3256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 9/100 [02:56<29:46, 19.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.004412 | Train MSE 0.0009 | Val MSE 3.1560 | Val MAE 7.4618 | Val MSE 154.6428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 10/100 [03:15<29:25, 19.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.004191 | Train MSE 0.0026 | Val MSE 7.2607 | Val MAE 10.8712 | Val MSE 355.7733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 11/100 [03:35<29:05, 19.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.003982 | Train MSE 0.0004 | Val MSE 3.4572 | Val MAE 6.2618 | Val MSE 169.4031\n",
            "Sample pred first 3 steps: [[-7.2017312e-05  5.0129741e-04]\n",
            " [ 2.9153936e-03 -9.5365942e-04]\n",
            " [ 3.5055839e-03 -4.0395707e-03]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 12/100 [03:55<28:46, 19.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.003783 | Train MSE 0.0001 | Val MSE 1.5210 | Val MAE 5.1580 | Val MSE 74.5266\n",
            "Validation improved: 1.834895 -> 1.520951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 13/100 [04:14<28:24, 19.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.003593 | Train MSE 0.0003 | Val MSE 21.3127 | Val MAE 19.0428 | Val MSE 1044.3233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 14/100 [04:34<28:04, 19.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.003414 | Train MSE 0.0026 | Val MSE 8.1365 | Val MAE 9.2712 | Val MSE 398.6872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 15/100 [04:53<27:45, 19.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.003243 | Train MSE 0.0007 | Val MSE 2.5195 | Val MAE 6.6722 | Val MSE 123.4576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 16/100 [05:13<27:26, 19.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.003081 | Train MSE 0.0003 | Val MSE 6.1778 | Val MAE 11.3904 | Val MSE 302.7141\n",
            "Sample pred first 3 steps: [[-0.01018067  0.00272926]\n",
            " [-0.02280096  0.01004304]\n",
            " [-0.05458922  0.02571731]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 17/100 [05:33<27:04, 19.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.002927 | Train MSE 0.0014 | Val MSE 10.6482 | Val MAE 16.1656 | Val MSE 521.7630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 18/100 [05:52<26:43, 19.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.002781 | Train MSE 0.0016 | Val MSE 38.8954 | Val MAE 30.9425 | Val MSE 1905.8741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 19/100 [06:12<26:23, 19.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.002641 | Train MSE 0.0033 | Val MSE 1.8121 | Val MAE 5.7142 | Val MSE 88.7925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 20/100 [06:31<26:05, 19.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.002509 | Train MSE 0.0002 | Val MSE 1.1862 | Val MAE 4.7268 | Val MSE 58.1228\n",
            "Validation improved: 1.520951 -> 1.186180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 21/100 [06:51<25:46, 19.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.002384 | Train MSE 0.0008 | Val MSE 1.1296 | Val MAE 4.2547 | Val MSE 55.3526\n",
            "Sample pred first 3 steps: [[-0.0006554  -0.00292525]\n",
            " [-0.0050273  -0.01056344]\n",
            " [-0.00078927 -0.01652931]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 1.186180 -> 1.129644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 22/100 [07:10<25:28, 19.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.002265 | Train MSE 0.0004 | Val MSE 1.5785 | Val MAE 5.0541 | Val MSE 77.3476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 23/100 [07:30<25:05, 19.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.002151 | Train MSE 0.0018 | Val MSE 3.0683 | Val MAE 8.1840 | Val MSE 150.3474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 24/100 [07:49<24:44, 19.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.002044 | Train MSE 0.0004 | Val MSE 2.0752 | Val MAE 6.1489 | Val MSE 101.6840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 25/100 [08:09<24:23, 19.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.001942 | Train MSE 0.0013 | Val MSE 2.9329 | Val MAE 7.3477 | Val MSE 143.7099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [08:28<24:04, 19.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.001845 | Train MSE 0.0014 | Val MSE 2.9348 | Val MAE 6.5427 | Val MSE 143.8060\n",
            "Sample pred first 3 steps: [[-0.00381515 -0.0069498 ]\n",
            " [-0.00972284 -0.01378775]\n",
            " [-0.01431381 -0.02448569]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 27/100 [08:48<23:37, 19.41s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.001752 | Train MSE 0.0013 | Val MSE 2.3629 | Val MAE 7.4691 | Val MSE 115.7813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 28/100 [09:07<23:11, 19.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.001665 | Train MSE 0.0062 | Val MSE 1.3981 | Val MAE 4.8309 | Val MSE 68.5045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 29/100 [09:26<22:47, 19.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.001582 | Train MSE 0.0011 | Val MSE 1.4734 | Val MAE 5.1856 | Val MSE 72.1968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 30/100 [09:45<22:24, 19.20s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.001502 | Train MSE 0.0010 | Val MSE 0.9698 | Val MAE 4.1873 | Val MSE 47.5203\n",
            "Validation improved: 1.129644 -> 0.969801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 31/100 [10:04<22:00, 19.14s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.001427 | Train MSE 0.0019 | Val MSE 4.4821 | Val MAE 8.7808 | Val MSE 219.6233\n",
            "Sample pred first 3 steps: [[ 0.0018134  -0.0037807 ]\n",
            " [ 0.02844033 -0.0141212 ]\n",
            " [ 0.03880011 -0.02281468]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 32/100 [10:23<21:41, 19.14s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.001356 | Train MSE 0.0010 | Val MSE 0.8062 | Val MAE 3.4230 | Val MSE 39.5050\n",
            "Validation improved: 0.969801 -> 0.806224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 33/100 [10:42<21:23, 19.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.001288 | Train MSE 0.0028 | Val MSE 1.4242 | Val MAE 4.9122 | Val MSE 69.7882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 34/100 [11:01<21:04, 19.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.001224 | Train MSE 0.0014 | Val MSE 0.5685 | Val MAE 3.0476 | Val MSE 27.8572\n",
            "Validation improved: 0.806224 -> 0.568515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 35/100 [11:20<20:45, 19.16s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.001163 | Train MSE 0.0083 | Val MSE 1.1950 | Val MAE 5.2194 | Val MSE 58.5554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 36/100 [11:40<20:24, 19.14s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.001104 | Train MSE 0.0043 | Val MSE 0.4839 | Val MAE 2.7606 | Val MSE 23.7118\n",
            "Sample pred first 3 steps: [[ 0.00554566 -0.00553234]\n",
            " [ 0.02286753  0.00327224]\n",
            " [ 0.02353904 -0.00262797]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.568515 -> 0.483915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 37/100 [11:59<20:04, 19.11s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.001049 | Train MSE 0.0030 | Val MSE 0.7308 | Val MAE 3.4047 | Val MSE 35.8071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 38/100 [12:18<19:47, 19.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.000997 | Train MSE 0.0067 | Val MSE 3.8259 | Val MAE 9.1030 | Val MSE 187.4682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 39/100 [12:37<19:33, 19.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.000947 | Train MSE 0.0074 | Val MSE 0.6371 | Val MAE 3.3112 | Val MSE 31.2160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 40/100 [13:25<27:43, 27.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.000900 | Train MSE 0.0037 | Val MSE 0.5643 | Val MAE 3.0212 | Val MSE 27.6497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 41/100 [13:44<24:44, 25.17s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.000855 | Train MSE 0.0132 | Val MSE 0.5981 | Val MAE 2.9647 | Val MSE 29.3071\n",
            "Sample pred first 3 steps: [[-0.01221197 -0.00720825]\n",
            " [-0.01102703 -0.01394634]\n",
            " [-0.00195505 -0.01716675]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 42/100 [25:56<3:49:19, 237.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.000812 | Train MSE 0.0118 | Val MSE 0.6695 | Val MAE 3.3790 | Val MSE 32.8075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 43/100 [26:16<2:43:29, 172.10s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.000771 | Train MSE 0.0183 | Val MSE 0.5603 | Val MAE 2.9844 | Val MSE 27.4525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 44/100 [26:35<1:57:50, 126.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.000733 | Train MSE 0.0332 | Val MSE 0.7372 | Val MAE 3.5995 | Val MSE 36.1228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 45/100 [26:54<1:26:11, 94.03s/epoch] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.000696 | Train MSE 0.0477 | Val MSE 0.4800 | Val MAE 2.6574 | Val MSE 23.5208\n",
            "Validation improved: 0.483915 -> 0.480016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 46/100 [27:17<1:05:15, 72.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.000661 | Train MSE 0.0513 | Val MSE 0.8515 | Val MAE 4.1050 | Val MSE 41.7235\n",
            "Sample pred first 3 steps: [[ 0.01134121 -0.0013166 ]\n",
            " [ 0.00509023  0.00659728]\n",
            " [-0.01547665  0.019642  ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 47/100 [27:39<50:52, 57.60s/epoch]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.000628 | Train MSE 0.0817 | Val MSE 1.1673 | Val MAE 4.7562 | Val MSE 57.1955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 48/100 [28:02<40:50, 47.12s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.000597 | Train MSE 0.1092 | Val MSE 0.9218 | Val MAE 3.7493 | Val MSE 45.1692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 49/100 [28:25<33:47, 39.75s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.000567 | Train MSE 1.5320 | Val MSE 2.0564 | Val MAE 6.0240 | Val MSE 100.7633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 50/100 [28:47<28:49, 34.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.000539 | Train MSE 0.6434 | Val MSE 0.8062 | Val MAE 3.6464 | Val MSE 39.5034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 51/100 [29:10<25:16, 30.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.000512 | Train MSE 0.9065 | Val MSE 1.1801 | Val MAE 4.2552 | Val MSE 57.8247\n",
            "Sample pred first 3 steps: [[-0.04192623  0.02327325]\n",
            " [-0.01558202  0.03660211]\n",
            " [ 0.02717655  0.03923628]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 52/100 [29:33<22:49, 28.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.000486 | Train MSE 0.8230 | Val MSE 0.6688 | Val MAE 3.2708 | Val MSE 32.7721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 53/100 [29:55<20:50, 26.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.000462 | Train MSE 0.6112 | Val MSE 0.5058 | Val MAE 2.6738 | Val MSE 24.7858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  54%|█████▍    | 54/100 [30:17<19:20, 25.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | LR 0.000439 | Train MSE 0.5159 | Val MSE 0.5067 | Val MAE 2.7234 | Val MSE 24.8295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▌    | 55/100 [30:39<18:16, 24.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | LR 0.000417 | Train MSE 0.4635 | Val MSE 0.4431 | Val MAE 2.5773 | Val MSE 21.7116\n",
            "Validation improved: 0.480016 -> 0.443094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  56%|█████▌    | 56/100 [31:01<17:24, 23.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | LR 0.000396 | Train MSE 0.4318 | Val MSE 0.4213 | Val MAE 2.3878 | Val MSE 20.6444\n",
            "Sample pred first 3 steps: [[0.02399179 0.01329268]\n",
            " [0.01166372 0.03080136]\n",
            " [0.01065866 0.0226118 ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.443094 -> 0.421315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 57/100 [31:24<16:45, 23.40s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | LR 0.000376 | Train MSE 0.4071 | Val MSE 0.3829 | Val MAE 2.2370 | Val MSE 18.7628\n",
            "Validation improved: 0.421315 -> 0.382915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  58%|█████▊    | 58/100 [31:46<16:09, 23.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | LR 0.000357 | Train MSE 0.3829 | Val MSE 0.3599 | Val MAE 2.1288 | Val MSE 17.6359\n",
            "Validation improved: 0.382915 -> 0.359917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▉    | 59/100 [32:09<15:39, 22.91s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | LR 0.000339 | Train MSE 0.3692 | Val MSE 0.3408 | Val MAE 2.1906 | Val MSE 16.6971\n",
            "Validation improved: 0.359917 -> 0.340758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  60%|██████    | 60/100 [32:31<15:11, 22.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | LR 0.000322 | Train MSE 0.3557 | Val MSE 0.3370 | Val MAE 2.2428 | Val MSE 16.5120\n",
            "Validation improved: 0.340758 -> 0.336980\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████    | 61/100 [32:54<14:46, 22.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | LR 0.000306 | Train MSE 0.3419 | Val MSE 0.3315 | Val MAE 2.1329 | Val MSE 16.2411\n",
            "Sample pred first 3 steps: [[0.01998217 0.0161657 ]\n",
            " [0.02068871 0.01760675]\n",
            " [0.02588302 0.00878574]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.336980 -> 0.331451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  62%|██████▏   | 62/100 [33:16<14:21, 22.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | LR 0.000291 | Train MSE 0.3344 | Val MSE 0.3006 | Val MAE 1.8918 | Val MSE 14.7303\n",
            "Validation improved: 0.331451 -> 0.300618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 63/100 [33:39<14:00, 22.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | LR 0.000276 | Train MSE 0.3206 | Val MSE 0.2920 | Val MAE 1.9205 | Val MSE 14.3086\n",
            "Validation improved: 0.300618 -> 0.292013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  64%|██████▍   | 64/100 [34:02<13:39, 22.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | LR 0.000263 | Train MSE 0.3237 | Val MSE 0.3267 | Val MAE 2.0881 | Val MSE 16.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 65/100 [34:25<13:17, 22.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | LR 0.000250 | Train MSE 0.3124 | Val MSE 0.3018 | Val MAE 1.9776 | Val MSE 14.7876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  66%|██████▌   | 66/100 [34:48<12:53, 22.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | LR 0.000237 | Train MSE 0.3070 | Val MSE 0.2743 | Val MAE 1.7295 | Val MSE 13.4394\n",
            "Sample pred first 3 steps: [[ 0.02490485  0.00530759]\n",
            " [-0.00742888  0.01629725]\n",
            " [-0.00891832  0.018665  ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.292013 -> 0.274275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  67%|██████▋   | 67/100 [35:10<12:31, 22.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | LR 0.000225 | Train MSE 0.3058 | Val MSE 0.3047 | Val MAE 2.0923 | Val MSE 14.9287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  68%|██████▊   | 68/100 [35:33<12:11, 22.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | LR 0.000214 | Train MSE 0.2995 | Val MSE 0.2905 | Val MAE 1.9381 | Val MSE 14.2335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  69%|██████▉   | 69/100 [35:56<11:43, 22.69s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 068 | LR 0.000203 | Train MSE 0.2992 | Val MSE 0.3173 | Val MAE 2.0528 | Val MSE 15.5497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  70%|███████   | 70/100 [36:18<11:18, 22.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 069 | LR 0.000193 | Train MSE 0.2964 | Val MSE 0.2754 | Val MAE 1.8177 | Val MSE 13.4922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  71%|███████   | 71/100 [36:41<11:00, 22.77s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070 | LR 0.000183 | Train MSE 0.2892 | Val MSE 0.2711 | Val MAE 1.8006 | Val MSE 13.2854\n",
            "Sample pred first 3 steps: [[0.02423834 0.00414589]\n",
            " [0.00667322 0.00939411]\n",
            " [0.01357022 0.01396515]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.274275 -> 0.271132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  72%|███████▏  | 72/100 [37:04<10:35, 22.69s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 071 | LR 0.000174 | Train MSE 0.2869 | Val MSE 0.2813 | Val MAE 1.8573 | Val MSE 13.7842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  73%|███████▎  | 73/100 [37:27<10:18, 22.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 072 | LR 0.000166 | Train MSE 0.2879 | Val MSE 0.2643 | Val MAE 1.7238 | Val MSE 12.9516\n",
            "Validation improved: 0.271132 -> 0.264319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  74%|███████▍  | 74/100 [37:50<09:50, 22.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 073 | LR 0.000157 | Train MSE 0.2873 | Val MSE 0.2645 | Val MAE 1.7293 | Val MSE 12.9610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  75%|███████▌  | 75/100 [38:12<09:25, 22.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 074 | LR 0.000149 | Train MSE 0.2815 | Val MSE 0.2679 | Val MAE 1.7414 | Val MSE 13.1280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  76%|███████▌  | 76/100 [38:34<09:00, 22.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 075 | LR 0.000142 | Train MSE 0.2799 | Val MSE 0.2572 | Val MAE 1.6890 | Val MSE 12.6020\n",
            "Sample pred first 3 steps: [[ 0.02341874 -0.00124   ]\n",
            " [ 0.00265679 -0.00360659]\n",
            " [ 0.00858107 -0.00272467]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.264319 -> 0.257185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  77%|███████▋  | 77/100 [38:56<08:36, 22.45s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 076 | LR 0.000135 | Train MSE 0.2766 | Val MSE 0.2592 | Val MAE 1.7108 | Val MSE 12.6991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  78%|███████▊  | 78/100 [39:19<08:13, 22.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 077 | LR 0.000128 | Train MSE 0.2768 | Val MSE 0.2579 | Val MAE 1.7560 | Val MSE 12.6373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  79%|███████▉  | 79/100 [39:41<07:50, 22.38s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 078 | LR 0.000122 | Train MSE 0.2704 | Val MSE 0.2506 | Val MAE 1.6505 | Val MSE 12.2816\n",
            "Validation improved: 0.257185 -> 0.250646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  80%|████████  | 80/100 [40:03<07:27, 22.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 079 | LR 0.000116 | Train MSE 0.2736 | Val MSE 0.2715 | Val MAE 1.8872 | Val MSE 13.3022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  81%|████████  | 81/100 [40:26<07:04, 22.35s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080 | LR 0.000110 | Train MSE 0.2695 | Val MSE 0.2540 | Val MAE 1.6865 | Val MSE 12.4457\n",
            "Sample pred first 3 steps: [[0.0233967  0.0053085 ]\n",
            " [0.00446602 0.0018596 ]\n",
            " [0.0113713  0.00757965]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  82%|████████▏ | 82/100 [40:48<06:41, 22.30s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 081 | LR 0.000104 | Train MSE 0.2695 | Val MSE 0.2668 | Val MAE 1.8574 | Val MSE 13.0708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  83%|████████▎ | 83/100 [41:10<06:18, 22.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 082 | LR 0.000099 | Train MSE 0.2647 | Val MSE 0.2493 | Val MAE 1.6430 | Val MSE 12.2174\n",
            "Validation improved: 0.250646 -> 0.249336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  84%|████████▍ | 84/100 [41:33<05:56, 22.31s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 083 | LR 0.000094 | Train MSE 0.2661 | Val MSE 0.2541 | Val MAE 1.6839 | Val MSE 12.4496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  85%|████████▌ | 85/100 [41:55<05:34, 22.29s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 084 | LR 0.000089 | Train MSE 0.2645 | Val MSE 0.2553 | Val MAE 1.6965 | Val MSE 12.5080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  86%|████████▌ | 86/100 [42:17<05:11, 22.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 085 | LR 0.000085 | Train MSE 0.2593 | Val MSE 0.2473 | Val MAE 1.6802 | Val MSE 12.1168\n",
            "Sample pred first 3 steps: [[ 0.01585218  0.01001518]\n",
            " [-0.00093783  0.00784181]\n",
            " [ 0.00595992  0.01379247]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.249336 -> 0.247281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  87%|████████▋ | 87/100 [42:39<04:49, 22.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 086 | LR 0.000081 | Train MSE 0.2605 | Val MSE 0.2441 | Val MAE 1.6181 | Val MSE 11.9618\n",
            "Validation improved: 0.247281 -> 0.244118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  88%|████████▊ | 88/100 [43:02<04:27, 22.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 087 | LR 0.000077 | Train MSE 0.2590 | Val MSE 0.2459 | Val MAE 1.6628 | Val MSE 12.0491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  89%|████████▉ | 89/100 [43:24<04:05, 22.29s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 088 | LR 0.000073 | Train MSE 0.2556 | Val MSE 0.2436 | Val MAE 1.6267 | Val MSE 11.9350\n",
            "Validation improved: 0.244118 -> 0.243571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  90%|█████████ | 90/100 [43:46<03:43, 22.34s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 089 | LR 0.000069 | Train MSE 0.2554 | Val MSE 0.2457 | Val MAE 1.6347 | Val MSE 12.0376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  91%|█████████ | 91/100 [44:09<03:22, 22.47s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090 | LR 0.000066 | Train MSE 0.2544 | Val MSE 0.2383 | Val MAE 1.6180 | Val MSE 11.6768\n",
            "Sample pred first 3 steps: [[0.01843885 0.01434825]\n",
            " [0.00243834 0.01267222]\n",
            " [0.00789142 0.01271246]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.243571 -> 0.238302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  92%|█████████▏| 92/100 [44:33<03:03, 22.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 091 | LR 0.000062 | Train MSE 0.2511 | Val MSE 0.2449 | Val MAE 1.6937 | Val MSE 11.9991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  93%|█████████▎| 93/100 [44:56<02:40, 22.95s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 092 | LR 0.000059 | Train MSE 0.2528 | Val MSE 0.2421 | Val MAE 1.6643 | Val MSE 11.8624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  94%|█████████▍| 94/100 [45:19<02:17, 22.83s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 093 | LR 0.000056 | Train MSE 0.2527 | Val MSE 0.2412 | Val MAE 1.6092 | Val MSE 11.8200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  95%|█████████▌| 95/100 [45:38<01:49, 21.84s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 094 | LR 0.000054 | Train MSE 0.2498 | Val MSE 0.2390 | Val MAE 1.6452 | Val MSE 11.7105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  96%|█████████▌| 96/100 [45:57<01:23, 20.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 095 | LR 0.000051 | Train MSE 0.2495 | Val MSE 0.2414 | Val MAE 1.6743 | Val MSE 11.8281\n",
            "Sample pred first 3 steps: [[ 0.01868537  0.01193879]\n",
            " [-0.00018033  0.00686492]\n",
            " [ 0.00853542  0.01215694]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  97%|█████████▋| 97/100 [46:16<01:00, 20.25s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 096 | LR 0.000048 | Train MSE 0.2491 | Val MSE 0.2346 | Val MAE 1.5949 | Val MSE 11.4955\n",
            "Validation improved: 0.238302 -> 0.234602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  98%|█████████▊| 98/100 [46:34<00:39, 19.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 097 | LR 0.000046 | Train MSE 0.2475 | Val MSE 0.2352 | Val MAE 1.5925 | Val MSE 11.5241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  99%|█████████▉| 99/100 [46:53<00:19, 19.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 098 | LR 0.000044 | Train MSE 0.2459 | Val MSE 0.2395 | Val MAE 1.6310 | Val MSE 11.7356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100/100 [47:12<00:00, 28.33s/epoch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 099 | LR 0.000041 | Train MSE 0.2435 | Val MSE 0.2358 | Val MAE 1.6364 | Val MSE 11.5538\n",
            "Val MSE: 11.4955\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AutoRegressiveLSTM(\n",
              "  (encoder): LSTM(5, 512, batch_first=True)\n",
              "  (decoder): LSTM(2, 512, batch_first=True)\n",
              "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = AutoRegressiveLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto14.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "data_science",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
